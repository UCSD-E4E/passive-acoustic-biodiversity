{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406a1103",
   "metadata": {},
   "source": [
    "# Articles\n",
    "https://keras.io/guides/transfer_learning/\n",
    "https://keras.io/guides/training_with_built_in_methods/\n",
    "https://www.youtube.com/watch?v=4umFSRPx-94&ab_channel=DigitalSreeni\n",
    "https://www.tensorflow.org/guide/saved_model\n",
    "https://github.com/UCSD-E4E/PyHa/blob/Microfaune_Retraining/Microfaune_Retraining-Copy1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f4dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bde0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2994afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8228002",
   "metadata": {},
   "source": [
    "## Load in BirdNET-Analyzer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9348a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to model folder, should have assets/variables/frozen pb graphs\n",
    "path_to_saved_model = \"./checkpoints/V2.1/BirdNET_GLOBAL_2K_V2.1_Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91862ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-3_ACT_1_layer_call_and_return_conditional_losses_28960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-2_ACT_1_layer_call_and_return_conditional_losses_31016) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-2_ACT_2_layer_call_and_return_conditional_losses_12037) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-2_ACT_1_layer_call_and_return_conditional_losses_11995) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-4_SE_CONV_1_layer_call_and_return_conditional_losses_29653) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-2_ACT_1_layer_call_and_return_conditional_losses_28443) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-4_ACT_2_layer_call_and_return_conditional_losses_29616) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-4_ACT_1_layer_call_and_return_conditional_losses_13373) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_1-2_ACT_1_layer_call_and_return_conditional_losses_26078) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-2_ACT_2_layer_call_and_return_conditional_losses_28582) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-3_ACT_1_layer_call_and_return_conditional_losses_31533) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_2-1_ACT_1_layer_call_and_return_conditional_losses_11405) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-3_ACT_2_layer_call_and_return_conditional_losses_29099) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-1_SE_CONV_1_layer_call_and_return_conditional_losses_11879) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_1-3_ACT_1_layer_call_and_return_conditional_losses_26390) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-4_ACT_2_layer_call_and_return_conditional_losses_12433) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-4_ACT_1_layer_call_and_return_conditional_losses_32050) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-1_SE_CONV_1_layer_call_and_return_conditional_losses_12861) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_2-3_ACT_1_layer_call_and_return_conditional_losses_27314) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_2-1_ACT_1_layer_call_and_return_conditional_losses_26702) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_1-1_ACT_1_layer_call_and_return_conditional_losses_25778) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_1-2_ACT_1_layer_call_and_return_conditional_losses_11201) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-2_SE_CONV_1_layer_call_and_return_conditional_losses_28619) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_2-4_ACT_1_layer_call_and_return_conditional_losses_27626) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_2-2_ACT_1_layer_call_and_return_conditional_losses_11499) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-4_SE_CONV_1_layer_call_and_return_conditional_losses_32226) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-5_ACT_2_layer_call_and_return_conditional_losses_30133) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-4_ACT_1_layer_call_and_return_conditional_losses_29477) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-5_ACT_1_layer_call_and_return_conditional_losses_12589) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-1_ACT_1_layer_call_and_return_conditional_losses_12787) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-3_ACT_2_layer_call_and_return_conditional_losses_31672) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-3_SE_CONV_1_layer_call_and_return_conditional_losses_31709) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_1-1_ACT_1_layer_call_and_return_conditional_losses_11107) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-5_ACT_2_layer_call_and_return_conditional_losses_12631) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-1_ACT_1_layer_call_and_return_conditional_losses_27938) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-3_ACT_1_layer_call_and_return_conditional_losses_13175) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-4_SE_CONV_1_layer_call_and_return_conditional_losses_13447) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-1_ACT_2_layer_call_and_return_conditional_losses_11847) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-2_ACT_2_layer_call_and_return_conditional_losses_13019) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-5_SE_CONV_1_layer_call_and_return_conditional_losses_30170) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-1_ACT_1_layer_call_and_return_conditional_losses_11805) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-1_ACT_2_layer_call_and_return_conditional_losses_30650) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-3_SE_CONV_1_layer_call_and_return_conditional_losses_29136) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-3_ACT_1_layer_call_and_return_conditional_losses_12193) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-2_SE_CONV_1_layer_call_and_return_conditional_losses_31192) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_2-3_ACT_1_layer_call_and_return_conditional_losses_11601) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-2_ACT_2_layer_call_and_return_conditional_losses_31155) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-2_SE_CONV_1_layer_call_and_return_conditional_losses_13051) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-4_ACT_2_layer_call_and_return_conditional_losses_13415) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-4_ACT_1_layer_call_and_return_conditional_losses_12391) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-3_SE_CONV_1_layer_call_and_return_conditional_losses_12267) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-2_SE_CONV_1_layer_call_and_return_conditional_losses_12069) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_2-4_ACT_1_layer_call_and_return_conditional_losses_11703) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-1_ACT_2_layer_call_and_return_conditional_losses_28077) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_2-2_ACT_1_layer_call_and_return_conditional_losses_27002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-4_SE_CONV_1_layer_call_and_return_conditional_losses_12465) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-1_ACT_1_layer_call_and_return_conditional_losses_30511) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-2_ACT_1_layer_call_and_return_conditional_losses_12977) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_4834) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-3_SE_CONV_1_layer_call_and_return_conditional_losses_13249) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-5_SE_CONV_1_layer_call_and_return_conditional_losses_12663) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-1_SE_CONV_1_layer_call_and_return_conditional_losses_28114) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-3_ACT_2_layer_call_and_return_conditional_losses_12235) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_1-3_ACT_1_layer_call_and_return_conditional_losses_11303) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-1_SE_CONV_1_layer_call_and_return_conditional_losses_30687) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_3-5_ACT_1_layer_call_and_return_conditional_losses_29994) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-4_ACT_2_layer_call_and_return_conditional_losses_32189) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-3_ACT_2_layer_call_and_return_conditional_losses_13217) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_BLOCK_4-1_ACT_2_layer_call_and_return_conditional_losses_12829) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(path_to_saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b611ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d242010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "INPUT (InputLayer)              [(None, 144000)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ADVANCED_SPEC1 (LinearSpecLayer (None, 128, 513, 1)  1           INPUT[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_SPEC_NOQUANT (BatchNormal (None, 128, 513, 1)  4           ADVANCED_SPEC1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "CONV_0 (Conv2D)                 (None, 64, 257, 30)  960         BNORM_SPEC_NOQUANT[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_0 (BatchNormalization)    (None, 64, 257, 30)  120         CONV_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "ACT_0 (Activation)              (None, 64, 257, 30)  0           BNORM_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_MAX (MaxPooling2D)       (None, 64, 128, 30)  0           ACT_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_AVG (AveragePooling2D)   (None, 64, 128, 30)  0           ACT_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_CONCAT (Concatenate)     (None, 64, 128, 60)  0           pool_0_MAX[0][0]                 \n",
      "                                                                 pool_0_AVG[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_ACT_QUANT (Activation)   (None, 64, 128, 60)  0           pool_0_CONCAT[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_CONV (Conv2D)            (None, 64, 128, 30)  1830        pool_0_ACT_QUANT[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_CONV_1 (Conv2D)       (None, 32, 64, 60)   16200       pool_0_CONV[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_CONV_1 (Conv2D)       (None, 32, 64, 60)   32400       BLOCK_1-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ADD (Add)             (None, 32, 64, 60)   0           BLOCK_1-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_1-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_CONV_1 (Conv2D)       (None, 32, 64, 60)   32400       BLOCK_1-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ADD (Add)             (None, 32, 64, 60)   0           BLOCK_1-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_1-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_CONV_1 (Conv2D)       (None, 16, 32, 240)  129600      BLOCK_1-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_1 (Conv2D)       (None, 16, 32, 640)  76800       BLOCK_2-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_1 (BatchNormalizat (None, 16, 32, 640)  2560        BLOCK_3-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_1 (Activation)    (None, 16, 32, 640)  0           BLOCK_3-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-1_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-1_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-1_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-1_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-1_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-1_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-1_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-1_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-1_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-2_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-2_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-2_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-2_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-2_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-2_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-2_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-2_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-2_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-3_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-3_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-3_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-3_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-3_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-3_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-3_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-3_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-3_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-4_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-4_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-4_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-4_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-4_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-4_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-4_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-4_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-4_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-5_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-5_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-5_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-5_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-5_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-5_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-5_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-5_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-5_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-5_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-5_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-5_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-5_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-5_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-5_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_1 (Conv2D)       (None, 8, 16, 1120)  179200      BLOCK_3-5_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_1 (BatchNormalizat (None, 8, 16, 1120)  4480        BLOCK_4-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_1 (Activation)    (None, 8, 16, 1120)  0           BLOCK_4-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-1_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-1_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-1_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-1_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-1_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-1_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-1_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-1_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-1_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-2_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-2_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-2_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-2_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-2_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-2_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-2_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-2_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-2_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-3_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-3_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-3_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-3_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-3_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-3_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-3_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-3_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-3_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-4_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-4_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-4_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-4_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-4_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-4_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-4_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-4_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-4_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_POST_NOQUANT (BatchNormal (None, 4, 8, 280)    1120        BLOCK_4-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ACT_POST (Activation)           (None, 4, 8, 280)    0           BNORM_POST_NOQUANT[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "POST_CONV_1 (Conv2D)            (None, 2, 6, 420)    1058400     ACT_POST[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "POST_BN_1 (BatchNormalization)  (None, 2, 6, 420)    1680        POST_CONV_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "POST_ACT_1 (Activation)         (None, 2, 6, 420)    0           POST_BN_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "GLOBAL_LME_POOL (GlobalLogExpPo (None, 420)          1           POST_ACT_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "CLASS_DENSE_1 (Dense)           (None, 2434)         1024714     GLOBAL_LME_POOL[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 7,604,470\n",
      "Trainable params: 7,564,848\n",
      "Non-trainable params: 39,622\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac2e0f",
   "metadata": {},
   "source": [
    "## Preprocess and load data\n",
    "According to `config.py` and `checkpoints/README.md` for V2.1:  \n",
    "- Model training input size: 144000 = 48000 x 3 = sample rate x num chunks  \n",
    "- Model training output size: 2434 = 2424 bird classes + 10 non-event classes\n",
    "- Visualize using [Netron](https://netron.app/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336323c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def splitSignal(sig, rate, overlap, seconds=3.0, minlen=1.5):\n",
    "\n",
    "    # Split signal with overlap\n",
    "    sig_splits = []\n",
    "    for i in range(0, len(sig), int((seconds - overlap) * rate)):\n",
    "        split = sig[i:i + int(seconds * rate)]\n",
    "\n",
    "        # End of signal?\n",
    "        if len(split) < int(minlen * rate):\n",
    "            break\n",
    "        \n",
    "        # Signal chunk too short? Fill with zeros.\n",
    "        if len(split) < int(rate * seconds):\n",
    "            temp = np.zeros((int(rate * seconds)))\n",
    "            temp[:len(split)] = split\n",
    "            split = temp\n",
    "        \n",
    "        sig_splits.append(split)\n",
    "\n",
    "    return sig_splits\n",
    "\n",
    "def readAudioData(path, overlap, sample_rate=48000):\n",
    "\n",
    "    #print('READING AUDIO DATA...', end=' ', flush=True)\n",
    "\n",
    "    # Open file with librosa (uses ffmpeg or libav)\n",
    "    try:\n",
    "        sig, rate = librosa.load(path, sr=sample_rate, mono=True, res_type='kaiser_fast')\n",
    "        clip_length = librosa.get_duration(y=sig, sr=rate)\n",
    "    except:\n",
    "        return 0\n",
    "    # Split audio into 3-second chunks\n",
    "    chunks = splitSignal(sig, rate, overlap)\n",
    "\n",
    "    print('DONE! READ', str(len(chunks)), 'CHUNKS.')\n",
    "\n",
    "    return chunks, clip_length\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#TODO Add mutliple species support for ROC curves \n",
    "def annotation_chunker_no_duplicates(kaleidoscope_df, chunk_length, include_no_bird=False, bird=None):\n",
    "    \"\"\"\n",
    "    Function that converts a Kaleidoscope-formatted Dataframe containing \n",
    "    annotations to uniform chunks of chunk_length. If there\n",
    "    are mutliple bird species in the same clip, this function creates chunks\n",
    "    for the more confident bird species.\n",
    "\n",
    "    Note: if all or part of an annotation covers the last < chunk_length\n",
    "    seconds of a clip it will be ignored. If two annotations overlap in \n",
    "    the same 3 second chunk, both are represented in that chunk\n",
    "    Args:\n",
    "        kaleidoscope_df (Dataframe)\n",
    "            - Dataframe of annotations in kaleidoscope format\n",
    "\n",
    "        chunk_length (int)\n",
    "            - duration to set all annotation chunks\n",
    "    Returns:\n",
    "        Dataframe of labels with chunk_length duration \n",
    "        (elements in \"OFFSET\" are divisible by chunk_length).\n",
    "    \"\"\"\n",
    "\n",
    "    #Init list of clips to cycle through and output dataframe\n",
    "    #kaleidoscope_df[\"FILEPATH\"] =  kaleidoscope_df[\"FOLDER\"] + kaleidoscope_df[\"IN FILE\"] \n",
    "    kaleidoscope_df['FILEPATH'] = kaleidoscope_df.loc[:,['FOLDER','IN FILE']].sum(axis=1)\n",
    "    clips = kaleidoscope_df[\"FILEPATH\"].unique()\n",
    "    df_columns = {'FOLDER': 'str', 'IN FILE' :'str', 'CLIP LENGTH' : 'float64', 'CHANNEL' : 'int64', 'OFFSET' : 'float64',\n",
    "                'DURATION' : 'float64', 'SAMPLE RATE' : 'int64','MANUAL ID' : 'str'}\n",
    "    output_df = pd.DataFrame({c: pd.Series(dtype=t) for c, t in df_columns.items()})\n",
    "    \n",
    "    # going through each clip\n",
    "    for clip in clips:\n",
    "        clip_df = kaleidoscope_df[kaleidoscope_df[\"FILEPATH\"] == clip]\n",
    "        path = clip_df[\"FOLDER\"].unique()[0]\n",
    "        file = clip_df[\"IN FILE\"].unique()[0]\n",
    "        birds = clip_df[\"MANUAL ID\"].unique()\n",
    "        sr = clip_df[\"SAMPLE RATE\"].unique()[0]\n",
    "        clip_len = clip_df[\"CLIP LENGTH\"].unique()[0]\n",
    "\n",
    "        # quick data sanitization to remove very short clips\n",
    "        # do not consider any chunk that is less than chunk_length\n",
    "        if clip_len < chunk_length:\n",
    "            continue\n",
    "        potential_annotation_count = int(clip_len)//int(chunk_length)\n",
    "\n",
    "        # going through each species that was ID'ed in the clip\n",
    "        arr_len = int(clip_len*1000)\n",
    "        species_df = clip_df#[clip_df[\"MANUAL ID\"] == bird]\n",
    "        human_arr = np.zeros((arr_len))\n",
    "        # looping through each annotation\n",
    "        #print(\"========================================\")\n",
    "        for annotation in species_df.index:\n",
    "            #print(species_df[\"OFFSET\"][annotation])\n",
    "            minval = int(round(species_df[\"OFFSET\"][annotation] * 1000, 0))\n",
    "            # Determining the end of a human label\n",
    "            maxval = int(\n",
    "                round(\n",
    "                    (species_df[\"OFFSET\"][annotation] +\n",
    "                        species_df[\"DURATION\"][annotation]) *\n",
    "                    1000,\n",
    "                    0))\n",
    "            # Placing the label relative to the clip\n",
    "            human_arr[minval:maxval] = 1\n",
    "        # performing the chunk isolation technique on the human array\n",
    "\n",
    "        for index in range(potential_annotation_count):\n",
    "            #print(\"=======================\")\n",
    "            #print(\"-----------------------------------------\")\n",
    "            #print(index)\n",
    "            chunk_start = index * (chunk_length*1000)\n",
    "            chunk_end = min((index+1)*chunk_length*1000,arr_len)\n",
    "            chunk = human_arr[int(chunk_start):int(chunk_end)]\n",
    "            if max(chunk) >= 0.5:\n",
    "                #Get row data\n",
    "                row = pd.DataFrame(index = [0])\n",
    "                annotation_start = chunk_start / 1000\n",
    "\n",
    "                #Handle birdnet output edge case\n",
    "                #print(\"-------------------------------------------\")\n",
    "                #print(sum(clip_df[\"DURATION\"] == 3))\n",
    "                #print(sum(clip_df[\"DURATION\"] == 3)/clip_df.shape[0])\n",
    "                #print(\"-------------------------------------------\")\n",
    "                if(sum(clip_df[\"DURATION\"] == 3)/clip_df.shape[0] == 1):\n",
    "                    #print(\"Processing here duration\")\n",
    "                    overlap = (clip_df[\"OFFSET\"]+0.5 >= (annotation_start)) & (clip_df[\"OFFSET\"]-0.5 <= (annotation_start))\n",
    "                    annotation_df = clip_df[overlap]\n",
    "                    #print(annotation_start, np.array(clip_df[\"OFFSET\"]), overlap)\n",
    "                    #print(annotation_df)\n",
    "                else:\n",
    "                    #print(\"Processing here\")\n",
    "                    overlap = is_overlap(clip_df[\"OFFSET\"], clip_df[\"OFFSET\"] + clip_df[\"DURATION\"], annotation_start, annotation_start + chunk_length)\n",
    "                    #print(overlap)\n",
    "                    annotation_df = clip_df[overlap]\n",
    "                    #print(annotation_df)\n",
    "                \n",
    "                #updating the dictionary\n",
    "                if ('CONFIDENCE' in clip_df.columns):\n",
    "                    annotation_df = annotation_df.sort_values(by=\"CONFIDENCE\", ascending=False)\n",
    "                    row[\"CONFIDENCE\"] = annotation_df.iloc[0][\"CONFIDENCE\"]\n",
    "                else:\n",
    "                    #The case of manual id, or there is an annotation with no known confidence\n",
    "                    row[\"CONFIDENCE\"] = 1\n",
    "                row[\"FOLDER\"] = path\n",
    "                row[\"IN FILE\"] = file\n",
    "                row[\"CLIP LENGTH\"] = clip_len\n",
    "                row[\"OFFSET\"] = annotation_start\n",
    "                row[\"DURATION\"] = chunk_length\n",
    "                row[\"SAMPLE RATE\"] = sr\n",
    "                row[\"MANUAL ID\"] = annotation_df.iloc[0][\"MANUAL ID\"] \n",
    "                row[\"CHANNEL\"] = 0\n",
    "                output_df = pd.concat([output_df,row], ignore_index=True)\n",
    "            elif(include_no_bird):\n",
    "                #print(max(chunk))\n",
    "                #Get row data\n",
    "                row = pd.DataFrame(index = [0])\n",
    "                annotation_start = chunk_start / 1000\n",
    "\n",
    "                #updating the dictionary\n",
    "                row[\"CONFIDENCE\"] = 0\n",
    "                row[\"FOLDER\"] = path\n",
    "                row[\"IN FILE\"] = file\n",
    "                row[\"CLIP LENGTH\"] = clip_len\n",
    "                row[\"OFFSET\"] = annotation_start\n",
    "                row[\"DURATION\"] = chunk_length\n",
    "                row[\"SAMPLE RATE\"] = sr\n",
    "                row[\"MANUAL ID\"] = \"no bird\"\n",
    "                row[\"CHANNEL\"] = 0\n",
    "                output_df = pd.concat([output_df,row], ignore_index=True)\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "\n",
    "def is_overlap(offset_df, end_df, chunk_start, chunk_end):\n",
    "    is_both_before = (chunk_end < offset_df) & (chunk_start < offset_df)\n",
    "    is_both_after = (end_df < chunk_end) & (end_df < chunk_start)\n",
    "    return (~is_both_before) & (~is_both_after)\n",
    "    \n",
    "    \n",
    "    interval = pd.Interval(left=offset_df, right=end_df)\n",
    "    print(interval)\n",
    "\n",
    "\n",
    "def split_save_files(dataframe_of_data):\n",
    "    chunked_df = annotation_chunker_no_duplicates(dataframe_of_data, 3, include_no_bird=True)\n",
    "    \n",
    "    \n",
    "    chunked_df.apply()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d25f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! READ 39 CHUNKS.\n"
     ]
    }
   ],
   "source": [
    "chunks,clip_length  = readAudioData(\"./Data/code-testing/XC628854 - Yellow-olive Flatbill - Tolmomyias sulphurescens.mp3\", 0, sample_rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3f2c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOLDER</th>\n",
       "      <th>IN FILE</th>\n",
       "      <th>CLIP LENGTH</th>\n",
       "      <th>CHANNEL</th>\n",
       "      <th>OFFSET</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>SAMPLE RATE</th>\n",
       "      <th>MANUAL ID</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC100027 - Southern Nightingale-Wren - Microce...</td>\n",
       "      <td>81.528167</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Microcerculus marginatus</td>\n",
       "      <td>0.155038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC100027 - Southern Nightingale-Wren - Microce...</td>\n",
       "      <td>81.528167</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Centropus celebensis</td>\n",
       "      <td>0.020985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC100027 - Southern Nightingale-Wren - Microce...</td>\n",
       "      <td>81.528167</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Meliphaga notata</td>\n",
       "      <td>0.027436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC100027 - Southern Nightingale-Wren - Microce...</td>\n",
       "      <td>81.528167</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Microcerculus marginatus</td>\n",
       "      <td>0.331647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC100027 - Southern Nightingale-Wren - Microce...</td>\n",
       "      <td>81.528167</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Sciaphylax hemimelaena</td>\n",
       "      <td>0.017806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39712</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC9881 - Blue-grey Tanager - Thraupis episcopu...</td>\n",
       "      <td>14.700021</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Thraupis episcopus</td>\n",
       "      <td>0.146423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39713</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC9881 - Blue-grey Tanager - Thraupis episcopu...</td>\n",
       "      <td>14.700021</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Pyrrhocorax pyrrhocorax</td>\n",
       "      <td>0.042745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39714</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC9881 - Blue-grey Tanager - Thraupis episcopu...</td>\n",
       "      <td>14.700021</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Thraupis sayaca</td>\n",
       "      <td>0.108350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39715</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC9881 - Blue-grey Tanager - Thraupis episcopu...</td>\n",
       "      <td>14.700021</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>no bird</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39716</th>\n",
       "      <td>.\\..\\Cosmos_data\\</td>\n",
       "      <td>XC99284 - Slate-throated Whitestart - Myioboru...</td>\n",
       "      <td>3.369813</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Ptilorrhoa leucosticta</td>\n",
       "      <td>0.033264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39717 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FOLDER                                            IN FILE  \\\n",
       "0      .\\..\\Cosmos_data\\  XC100027 - Southern Nightingale-Wren - Microce...   \n",
       "1      .\\..\\Cosmos_data\\  XC100027 - Southern Nightingale-Wren - Microce...   \n",
       "2      .\\..\\Cosmos_data\\  XC100027 - Southern Nightingale-Wren - Microce...   \n",
       "3      .\\..\\Cosmos_data\\  XC100027 - Southern Nightingale-Wren - Microce...   \n",
       "4      .\\..\\Cosmos_data\\  XC100027 - Southern Nightingale-Wren - Microce...   \n",
       "...                  ...                                                ...   \n",
       "39712  .\\..\\Cosmos_data\\  XC9881 - Blue-grey Tanager - Thraupis episcopu...   \n",
       "39713  .\\..\\Cosmos_data\\  XC9881 - Blue-grey Tanager - Thraupis episcopu...   \n",
       "39714  .\\..\\Cosmos_data\\  XC9881 - Blue-grey Tanager - Thraupis episcopu...   \n",
       "39715  .\\..\\Cosmos_data\\  XC9881 - Blue-grey Tanager - Thraupis episcopu...   \n",
       "39716  .\\..\\Cosmos_data\\  XC99284 - Slate-throated Whitestart - Myioboru...   \n",
       "\n",
       "       CLIP LENGTH  CHANNEL  OFFSET  DURATION  SAMPLE RATE  \\\n",
       "0        81.528167        0     0.0       3.0        48000   \n",
       "1        81.528167        0     3.0       3.0        48000   \n",
       "2        81.528167        0     6.0       3.0        48000   \n",
       "3        81.528167        0     9.0       3.0        48000   \n",
       "4        81.528167        0    12.0       3.0        48000   \n",
       "...            ...      ...     ...       ...          ...   \n",
       "39712    14.700021        0     0.0       3.0        48000   \n",
       "39713    14.700021        0     3.0       3.0        48000   \n",
       "39714    14.700021        0     6.0       3.0        48000   \n",
       "39715    14.700021        0     9.0       3.0        48000   \n",
       "39716     3.369813        0     0.0       3.0        48000   \n",
       "\n",
       "                      MANUAL ID  CONFIDENCE  \n",
       "0      Microcerculus marginatus    0.155038  \n",
       "1          Centropus celebensis    0.020985  \n",
       "2              Meliphaga notata    0.027436  \n",
       "3      Microcerculus marginatus    0.331647  \n",
       "4        Sciaphylax hemimelaena    0.017806  \n",
       "...                         ...         ...  \n",
       "39712        Thraupis episcopus    0.146423  \n",
       "39713   Pyrrhocorax pyrrhocorax    0.042745  \n",
       "39714           Thraupis sayaca    0.108350  \n",
       "39715                   no bird    0.000000  \n",
       "39716    Ptilorrhoa leucosticta    0.033264  \n",
       "\n",
       "[39717 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Siloux/Desktop/E4E/passive-acoustic-biodiversity/TweetyNET/cosmos_data/cosmos_random_sample_processing/automated_cosmos_tweety_to_birdnet.csv\")\n",
    "chunked_df = annotation_chunker_no_duplicates(data, 3, include_no_bird=True)\n",
    "chunked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee0d92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_file = pd.read_csv(\"C:/Users/Siloux/Desktop/E4E/PyHa/autoamted_cosmos_tweety_to_file.csv\")\n",
    "classes_of_interest = np.unique(to_file[\"MANUAL ID\"])\n",
    "chunked_df = chunked_df[(chunked_df[\"MANUAL ID\"].isin(classes_of_interest))]#[\"MANUAL_ID\"] = \"bird\"\n",
    "len(np.unique(chunked_df[\"MANUAL ID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e9e85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_df[\"FOLDER\"] = \"./Data/code-testing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49259256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! READ 39 CHUNKS.\n",
      "a must be greater than 0 unless no samples are taken\n",
      "a must be greater than 0 unless no samples are taken\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([ 0.        ,  0.        ,  0.        , ..., -0.00122339,\n",
       "         -0.00041645, -0.00049684], dtype=float32),\n",
       "  array([-0.00054962,  0.00087783,  0.00216126, ..., -0.00060256,\n",
       "          0.00029474,  0.00108685], dtype=float32),\n",
       "  array([ 0.00134224,  0.00134801,  0.00113327, ..., -0.00163486,\n",
       "         -0.00103791, -0.00083348], dtype=float32),\n",
       "  array([-0.00030538,  0.00077696,  0.00186265, ...,  0.00262075,\n",
       "          0.00142806,  0.00146308], dtype=float32),\n",
       "  array([0.00219837, 0.0019769 , 0.00159717, ..., 0.00185045, 0.00194336,\n",
       "         0.00275659], dtype=float32),\n",
       "  array([ 0.00201688, -0.00056329, -0.0024023 , ...,  0.01364738,\n",
       "          0.0114228 ,  0.0069463 ], dtype=float32),\n",
       "  array([ 4.3002030e-04, -8.1077758e-03, -1.5722346e-02, ...,\n",
       "          6.3503889e-04,  9.9656964e-04,  6.2260133e-06], dtype=float32),\n",
       "  array([-0.00119472, -0.00186244, -0.00263428, ...,  0.00135381,\n",
       "          0.0013627 ,  0.00026072], dtype=float32),\n",
       "  array([-0.00036479, -0.00023118, -0.00116165, ..., -0.00225793,\n",
       "         -0.00053361,  0.0027245 ], dtype=float32),\n",
       "  array([0.00485006, 0.00482748, 0.00391337, ..., 0.00426903, 0.00430605,\n",
       "         0.00130507], dtype=float32),\n",
       "  array([-0.00161547, -0.00285003, -0.0031479 , ...,  0.00290729,\n",
       "          0.00221114,  0.00041718], dtype=float32),\n",
       "  array([-0.00149216, -0.00205622, -0.00185383, ...,  0.02905481,\n",
       "          0.02513099,  0.01425627], dtype=float32),\n",
       "  array([0.02758732, 0.04046667, 0.05045103, ..., 0.00514496, 0.00435247,\n",
       "         0.00357025], dtype=float32),\n",
       "  array([ 0.0017678 , -0.00054325, -0.00161098, ...,  0.00553303,\n",
       "          0.00528749,  0.00446017], dtype=float32),\n",
       "  array([ 0.00289971, -0.00027195, -0.00397511, ..., -0.00159998,\n",
       "          0.00024876,  0.0015236 ], dtype=float32),\n",
       "  array([ 0.00088874, -0.0005915 , -0.00233662, ...,  0.00438146,\n",
       "          0.002564  ,  0.00128405], dtype=float32),\n",
       "  array([ 0.00030594, -0.00079489, -0.00157691, ...,  0.00089145,\n",
       "         -0.00075894, -0.00165804], dtype=float32),\n",
       "  array([-0.00103376, -0.00016785,  0.00087994, ..., -0.00273604,\n",
       "         -0.00279648, -0.00067845], dtype=float32),\n",
       "  array([0.00152477, 0.00184625, 0.0012721 , ..., 0.00110051, 0.00212073,\n",
       "         0.00166527], dtype=float32),\n",
       "  array([-0.00052048, -0.00150199, -0.00043986, ..., -0.00033681,\n",
       "         -0.00030597,  0.00045423], dtype=float32),\n",
       "  array([ 0.00048796, -0.00118449, -0.00172058, ...,  0.00028729,\n",
       "         -0.0003347 , -0.00096216], dtype=float32),\n",
       "  array([-0.00216473, -0.00338505, -0.00350383, ..., -0.00180851,\n",
       "         -0.00111632, -0.00032471], dtype=float32),\n",
       "  array([ 0.00070441,  0.00225613,  0.00375917, ...,  0.00051932,\n",
       "         -0.00136896, -0.00160485], dtype=float32),\n",
       "  array([-0.00106632, -0.00165318, -0.00210768, ..., -0.00092284,\n",
       "          0.00083734,  0.00143753], dtype=float32),\n",
       "  array([ 0.00039242, -0.00035297, -0.00016726, ..., -0.0046884 ,\n",
       "         -0.00336329,  0.00291471], dtype=float32),\n",
       "  array([ 0.00726182,  0.00481108, -0.00190165, ...,  0.00100736,\n",
       "         -0.00020801, -0.00180442], dtype=float32),\n",
       "  array([-0.00351324, -0.00385229, -0.00249124, ..., -0.00174041,\n",
       "         -0.00166388, -0.00161698], dtype=float32),\n",
       "  array([-0.00060756,  0.00113743,  0.00224845, ..., -0.00014866,\n",
       "         -0.00079001, -0.00026261], dtype=float32),\n",
       "  array([ 0.00020842,  0.00025406,  0.00092664, ..., -0.00143613,\n",
       "         -0.00117609,  0.00010311], dtype=float32),\n",
       "  array([ 0.0017151 ,  0.00305198,  0.00341559, ...,  0.00160987,\n",
       "          0.00040278, -0.00079726], dtype=float32),\n",
       "  array([-0.00088385, -0.00036177,  0.00033463, ...,  0.00259875,\n",
       "         -0.00020894, -0.0043407 ], dtype=float32),\n",
       "  array([-0.00491502, -0.00122129,  0.00261468, ..., -0.00100462,\n",
       "         -0.00162063, -0.00085534], dtype=float32),\n",
       "  array([ 0.00036341,  0.00051415,  0.00042626, ..., -0.00116821,\n",
       "         -0.00013797,  0.00024671], dtype=float32),\n",
       "  array([-0.00036431, -0.00033182,  0.00052072, ..., -0.00144379,\n",
       "         -0.00131037, -0.0011144 ], dtype=float32),\n",
       "  array([-0.00024435,  0.00049659,  0.00046859, ..., -0.00094429,\n",
       "          0.00212899,  0.00373677], dtype=float32),\n",
       "  array([ 0.00430433,  0.00473556,  0.0036698 , ..., -0.00256654,\n",
       "         -0.003216  , -0.00241336], dtype=float32),\n",
       "  array([-0.00173771, -0.00150881, -0.00052083, ..., -0.00044005,\n",
       "         -0.00200539, -0.00282954], dtype=float32)],\n",
       " [5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5],\n",
       " [33042,\n",
       "  33043,\n",
       "  33044,\n",
       "  33045,\n",
       "  33046,\n",
       "  33047,\n",
       "  33048,\n",
       "  33049,\n",
       "  33050,\n",
       "  33051,\n",
       "  33052,\n",
       "  33053,\n",
       "  33055,\n",
       "  33056,\n",
       "  33057,\n",
       "  33058,\n",
       "  33059,\n",
       "  33060,\n",
       "  33061,\n",
       "  33062,\n",
       "  33064,\n",
       "  33065,\n",
       "  33066,\n",
       "  33067,\n",
       "  33068,\n",
       "  33069,\n",
       "  33070,\n",
       "  33071,\n",
       "  33072,\n",
       "  33073,\n",
       "  33074,\n",
       "  33075,\n",
       "  33076,\n",
       "  33077,\n",
       "  33078,\n",
       "  33079,\n",
       "  33080])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_of_interests = list(np.unique(chunked_df[\"MANUAL ID\"]))\n",
    "chunked_df[\"y\"] = chunked_df[\"MANUAL ID\"].apply(lambda x: species_of_interests.index(x))\n",
    "chunked_df\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "UID = []\n",
    "\n",
    "#assume df is chunked\n",
    "for file in np.unique(chunked_df[\"IN FILE\"]):\n",
    "    file_df = chunked_df[chunked_df[\"IN FILE\"] == file]\n",
    "    #print((file_df[\"FOLDER\"] + file_df[\"IN FILE\"]).iloc[0])\n",
    "    try:\n",
    "        chunks, clip_length = readAudioData((file_df[\"FOLDER\"] + file_df[\"IN FILE\"]).iloc[0], 0, sample_rate=48000)\n",
    "    except:\n",
    "        continue\n",
    "    offset = 0\n",
    "    for c in range(len(chunks)):\n",
    "        offset = c * 3\n",
    "        try:\n",
    "            chunk_df = file_df[file_df[\"OFFSET\"] == offset].sample(1)\n",
    "            if (chunk_df.empty):\n",
    "                break\n",
    "            # Add to batch\n",
    "            X.append(chunks[c])\n",
    "            Y.append(chunk_df[\"y\"].iloc[0])\n",
    "            UID.append(chunk_df.index[0])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        \n",
    "X, Y, UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ed0255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        ,  0.        ,  0.        , ..., -0.00122339,\n",
       "         -0.00041645, -0.00049684],\n",
       "        [-0.00054962,  0.00087783,  0.00216126, ..., -0.00060256,\n",
       "          0.00029474,  0.00108685],\n",
       "        [ 0.00134224,  0.00134801,  0.00113327, ..., -0.00163486,\n",
       "         -0.00103791, -0.00083348],\n",
       "        ...,\n",
       "        [-0.00024435,  0.00049659,  0.00046859, ..., -0.00094429,\n",
       "          0.00212899,  0.00373677],\n",
       "        [ 0.00430433,  0.00473556,  0.0036698 , ..., -0.00256654,\n",
       "         -0.003216  , -0.00241336],\n",
       "        [-0.00173771, -0.00150881, -0.00052083, ..., -0.00044005,\n",
       "         -0.00200539, -0.00282954]], dtype=float32),\n",
       " array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]),\n",
       " [33042,\n",
       "  33043,\n",
       "  33044,\n",
       "  33045,\n",
       "  33046,\n",
       "  33047,\n",
       "  33048,\n",
       "  33049,\n",
       "  33050,\n",
       "  33051,\n",
       "  33052,\n",
       "  33053,\n",
       "  33055,\n",
       "  33056,\n",
       "  33057,\n",
       "  33058,\n",
       "  33059,\n",
       "  33060,\n",
       "  33061,\n",
       "  33062,\n",
       "  33064,\n",
       "  33065,\n",
       "  33066,\n",
       "  33067,\n",
       "  33068,\n",
       "  33069,\n",
       "  33070,\n",
       "  33071,\n",
       "  33072,\n",
       "  33073,\n",
       "  33074,\n",
       "  33075,\n",
       "  33076,\n",
       "  33077,\n",
       "  33078,\n",
       "  33079,\n",
       "  33080])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = {\"X\":X, \"Y\": Y, \"uids\": UID}\n",
    "inds = [i for i, x in enumerate(dataset[\"X\"])]\n",
    "X = np.array([dataset[\"X\"][i].transpose() for i in inds])\n",
    "Y = np.array([int(dataset[\"Y\"][i]) for i in inds])\n",
    "uids = [dataset[\"uids\"][i] for i in inds]\n",
    "X, Y, uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eef3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "def split_dataset(X, Y, test_size=0.2, random_state=0):\n",
    "    split_generator = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    ind_train, ind_test = next(split_generator.split(X, Y))\n",
    "    X_train, X_test = X[ind_train], X[ind_test]\n",
    "    Y_train, Y_test = Y[ind_train], Y[ind_test]\n",
    "    return ind_train, ind_test\n",
    "\n",
    "ind_train_val, ind_test = split_dataset(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c88f477e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([27, 34,  7, 11,  8, 36, 17, 24,  1,  6, 33,  2, 15, 29, 28, 31, 13,\n",
       "        12, 16,  5, 32, 10, 14, 30, 23, 26, 25, 20, 22], dtype=int64),\n",
       " array([ 4,  3,  9, 21, 35, 19,  0, 18], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_train_val, ind_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f95732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  Counter({5: 29})\n",
      "Test set:  Counter({5: 8})\n"
     ]
    }
   ],
   "source": [
    "#TODO ACTUALLY CREATE A VALIDATION TEST SET\n",
    "from collections import Counter\n",
    "X_train, Y_train = X[ind_train_val, np.newaxis], Y[ind_train_val]\n",
    "X_test,  Y_test =  X[ind_test, np.newaxis], Y[ind_test]          \n",
    "                    \n",
    "\n",
    "print(\"Training set: \", Counter(Y_train))\n",
    "print(\"Test set: \", Counter(Y_test))\n",
    "#print(\"Validation set: \", Counter(Y_val))\n",
    "#very imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e36e8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Celeus grammicus',\n",
       " 'Microcerculus marginatus',\n",
       " 'Myioborus miniatus',\n",
       " 'Ramphastos tucanus',\n",
       " 'Thraupis episcopus',\n",
       " 'Tolmomyias sulphurescens',\n",
       " 'Trogon viridis',\n",
       " 'Turdus leucomelas',\n",
       " 'Xiphorhynchus guttatus',\n",
       " 'Zonotrichia capensis']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_of_interests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74fc1e",
   "metadata": {},
   "source": [
    "## Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdfeedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, X, Y, batch_size=32, output_size=10):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n = len(Y)\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        print(\"RUNNINGS\", int(np.floor(self.n)/self.batch_size))\n",
    "        return int(np.floor(self.n)/self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_inds = self.inds[self.batch_size*index:self.batch_size*(index+1)]\n",
    "        #print(batch_inds)\n",
    "        self.counter += self.batch_size\n",
    "        if self.counter >= self.n:\n",
    "            self.shuffle()\n",
    "            \n",
    "        #TODO: FIX SO BATCH IS MORE THAN 1\n",
    "        raw_labels = np.array([self.Y[batch_inds][0]])\n",
    "        formatted_labels = np.zeros(self.output_size)\n",
    "        formatted_labels[self.Y[batch_inds][0]] = 1\n",
    "        fprmatted_labels = np.array([formatted_labels])\n",
    "        #print(formatted_labels.shape)\n",
    "        #print(np.array([formatted_labels]).shape)\n",
    "        #print(self.X[batch_inds, ...][0].shape)\n",
    "        \n",
    "        #print(tf.convert_to_tensor(self.X[batch_inds, ...][0]), tf.convert_to_tensor(np.array([formatted_labels])))\n",
    "        return tf.convert_to_tensor(self.X[batch_inds, ...][0]), tf.convert_to_tensor(np.array([formatted_labels]))\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.inds = np.random.permutation(self.n)\n",
    "        self.counter = 0\n",
    "# if train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b98ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, Flatten, ZeroPadding2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "def flat_sigmoid(x, sensitivity=-1):\n",
    "    return 1 / (1.0 + K.exp(sensitivity * K.clip(x, -15, 15)))\n",
    "\n",
    "def flat_sigmod_binary_crossentropy(y_true, y_pred):\n",
    "    sensitivity=-1\n",
    "    print(\"RUNNING CUSTOM LOSS\")\n",
    "    print(y_pred)\n",
    "    y_pred = 1 / (1.0 + K.exp(sensitivity * K.clip(y_pred, -15, 15)))\n",
    "    #print(min(y_pred), max(y_pred))\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    \n",
    "    return bce(y_true, y_pred)\n",
    "\n",
    "def customLoss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "\n",
    "\n",
    "class birdnet_flat_sigmod(tf.keras.Model):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(birdnet_flat_sigmod, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self._trainable = True\n",
    "    \n",
    "    def call(self, x):\n",
    "        sensitivity = -1\n",
    "        x = self.pretrained(x)\n",
    "        x = 1 / (1.0 + K.exp(sensitivity * K.clip(x, -15, 15)))\n",
    "        return x \n",
    "    \n",
    "class sigmod(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(sigmod, self).__init__()\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return 1 / (1.0 + K.exp(sensitivity * K.clip(inputs, -15, 15))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fbb3693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "INPUT (InputLayer)              [(None, 144000)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ADVANCED_SPEC1 (LinearSpecLayer (None, 128, 513, 1)  1           INPUT[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_SPEC_NOQUANT (BatchNormal (None, 128, 513, 1)  4           ADVANCED_SPEC1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "CONV_0 (Conv2D)                 (None, 64, 257, 30)  960         BNORM_SPEC_NOQUANT[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_0 (BatchNormalization)    (None, 64, 257, 30)  120         CONV_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "ACT_0 (Activation)              (None, 64, 257, 30)  0           BNORM_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_MAX (MaxPooling2D)       (None, 64, 128, 30)  0           ACT_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_AVG (AveragePooling2D)   (None, 64, 128, 30)  0           ACT_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_CONCAT (Concatenate)     (None, 64, 128, 60)  0           pool_0_MAX[0][0]                 \n",
      "                                                                 pool_0_AVG[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_ACT_QUANT (Activation)   (None, 64, 128, 60)  0           pool_0_CONCAT[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_CONV (Conv2D)            (None, 64, 128, 30)  1830        pool_0_ACT_QUANT[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_CONV_1 (Conv2D)       (None, 32, 64, 60)   16200       pool_0_CONV[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_CONV_1 (Conv2D)       (None, 32, 64, 60)   32400       BLOCK_1-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ADD (Add)             (None, 32, 64, 60)   0           BLOCK_1-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_1-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_CONV_1 (Conv2D)       (None, 32, 64, 60)   32400       BLOCK_1-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ADD (Add)             (None, 32, 64, 60)   0           BLOCK_1-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_1-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_CONV_1 (Conv2D)       (None, 16, 32, 240)  129600      BLOCK_1-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_1 (Conv2D)       (None, 16, 32, 640)  76800       BLOCK_2-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_1 (BatchNormalizat (None, 16, 32, 640)  2560        BLOCK_3-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_1 (Activation)    (None, 16, 32, 640)  0           BLOCK_3-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-1_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-1_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-1_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-1_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-1_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-1_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-1_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-1_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-1_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-2_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-2_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-2_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-2_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-2_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-2_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-2_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-2_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-2_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-3_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-3_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-3_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-3_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-3_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-3_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-3_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-3_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-3_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-4_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-4_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-4_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-4_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-4_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-4_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-4_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-4_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-4_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-5_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-5_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-5_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-5_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-5_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-5_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-5_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-5_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-5_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-5_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-5_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-5_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-5_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-5_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-5_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_1 (Conv2D)       (None, 8, 16, 1120)  179200      BLOCK_3-5_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_1 (BatchNormalizat (None, 8, 16, 1120)  4480        BLOCK_4-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_1 (Activation)    (None, 8, 16, 1120)  0           BLOCK_4-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-1_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-1_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-1_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-1_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-1_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-1_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-1_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-1_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-1_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-2_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-2_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-2_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-2_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-2_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-2_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-2_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-2_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-2_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-3_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-3_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-3_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-3_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-3_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-3_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-3_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-3_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-3_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-4_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-4_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-4_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-4_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-4_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-4_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-4_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-4_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-4_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_POST_NOQUANT (BatchNormal (None, 4, 8, 280)    1120        BLOCK_4-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ACT_POST (Activation)           (None, 4, 8, 280)    0           BNORM_POST_NOQUANT[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "POST_CONV_1 (Conv2D)            (None, 2, 6, 420)    1058400     ACT_POST[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "POST_BN_1 (BatchNormalization)  (None, 2, 6, 420)    1680        POST_CONV_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "POST_ACT_1 (Activation)         (None, 2, 6, 420)    0           POST_BN_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "GLOBAL_LME_POOL (GlobalLogExpPo (None, 420)          1           POST_ACT_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "its_new_lmao (Dense)            (None, 10)           4210        GLOBAL_LME_POOL[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 6,583,966\n",
      "Trainable params: 6,544,344\n",
      "Non-trainable params: 39,622\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = model.layers[-2].output\n",
    "o = tf.keras.layers.Dense(len(species_of_interests), activation='sigmoid', name='its_new_lmao')(x)\n",
    "\n",
    "model3 = Model(inputs=model.input, outputs=o)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c275c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "INPUT (InputLayer)              [(None, 144000)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ADVANCED_SPEC1 (LinearSpecLayer (None, 128, 513, 1)  1           INPUT[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_SPEC_NOQUANT (BatchNormal (None, 128, 513, 1)  4           ADVANCED_SPEC1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "CONV_0 (Conv2D)                 (None, 64, 257, 30)  960         BNORM_SPEC_NOQUANT[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_0 (BatchNormalization)    (None, 64, 257, 30)  120         CONV_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "ACT_0 (Activation)              (None, 64, 257, 30)  0           BNORM_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_MAX (MaxPooling2D)       (None, 64, 128, 30)  0           ACT_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_AVG (AveragePooling2D)   (None, 64, 128, 30)  0           ACT_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_CONCAT (Concatenate)     (None, 64, 128, 60)  0           pool_0_MAX[0][0]                 \n",
      "                                                                 pool_0_AVG[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_ACT_QUANT (Activation)   (None, 64, 128, 60)  0           pool_0_CONCAT[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool_0_CONV (Conv2D)            (None, 64, 128, 30)  1830        pool_0_ACT_QUANT[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_CONV_1 (Conv2D)       (None, 32, 64, 60)   16200       pool_0_CONV[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-1_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_CONV_1 (Conv2D)       (None, 32, 64, 60)   32400       BLOCK_1-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-2_ADD (Add)             (None, 32, 64, 60)   0           BLOCK_1-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_1-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_CONV_1 (Conv2D)       (None, 32, 64, 60)   32400       BLOCK_1-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_BN_1 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ACT_1 (Activation)    (None, 32, 64, 60)   0           BLOCK_1-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ACT_QUANT (Activation (None, 32, 64, 60)   0           BLOCK_1-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_CONV_3 (Conv2D)       (None, 32, 64, 60)   3600        BLOCK_1-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_BN_3 (BatchNormalizat (None, 32, 64, 60)   240         BLOCK_1-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_1-3_ADD (Add)             (None, 32, 64, 60)   0           BLOCK_1-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_1-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_CONV_1 (Conv2D)       (None, 16, 32, 240)  129600      BLOCK_1-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-1_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-2_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-3_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_CONV_1 (Conv2D)       (None, 16, 32, 240)  259200      BLOCK_2-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_BN_1 (BatchNormalizat (None, 16, 32, 240)  960         BLOCK_2-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ACT_1 (Activation)    (None, 16, 32, 240)  0           BLOCK_2-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ACT_QUANT (Activation (None, 16, 32, 240)  0           BLOCK_2-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_CONV_3 (Conv2D)       (None, 16, 32, 120)  28800       BLOCK_2-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_BN_3 (BatchNormalizat (None, 16, 32, 120)  480         BLOCK_2-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_2-4_ADD (Add)             (None, 16, 32, 120)  0           BLOCK_2-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_2-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_1 (Conv2D)       (None, 16, 32, 640)  76800       BLOCK_2-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_1 (BatchNormalizat (None, 16, 32, 640)  2560        BLOCK_3-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_1 (Activation)    (None, 16, 32, 640)  0           BLOCK_3-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-1_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-1_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-1_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-1_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-1_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-1_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-1_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-1_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-1_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-1_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-2_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-2_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-2_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-2_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-2_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-2_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-2_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-2_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-2_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-2_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-3_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-3_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-3_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-3_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-3_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-3_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-3_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-3_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-3_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-3_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-4_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-4_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-4_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-4_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-4_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-4_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-4_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-4_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-4_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-4_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_1 (Conv2D)       (None, 8, 16, 640)   102400      BLOCK_3-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_1 (BatchNormalizat (None, 8, 16, 640)   2560        BLOCK_3-5_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_1 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-5_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_2 (DepthwiseConv (None, 8, 16, 640)   5760        BLOCK_3-5_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_2_NOQUANT (BatchNo (None, 8, 16, 640)   2560        BLOCK_3-5_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_2 (Activation)    (None, 8, 16, 640)   0           BLOCK_3-5_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_AVG_POOL_1 (Global (None, 640)          0           BLOCK_3-5_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_RESHAPE (Reshape)  (None, 1, 1, 640)    0           BLOCK_3-5_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_CONV_1 (Conv2D)    (None, 1, 1, 40)     25600       BLOCK_3-5_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_SE_CONV_2 (Conv2D)    (None, 1, 1, 640)    25600       BLOCK_3-5_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_MULTIPLY (Multiply)   (None, 8, 16, 640)   0           BLOCK_3-5_ACT_2[0][0]            \n",
      "                                                                 BLOCK_3-5_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ACT_QUANT (Activation (None, 8, 16, 640)   0           BLOCK_3-5_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_CONV_3 (Conv2D)       (None, 8, 16, 160)   102400      BLOCK_3-5_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_BN_3 (BatchNormalizat (None, 8, 16, 160)   640         BLOCK_3-5_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_3-5_ADD (Add)             (None, 8, 16, 160)   0           BLOCK_3-5_BN_3[0][0]             \n",
      "                                                                 BLOCK_3-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_1 (Conv2D)       (None, 8, 16, 1120)  179200      BLOCK_3-5_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_1 (BatchNormalizat (None, 8, 16, 1120)  4480        BLOCK_4-1_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_1 (Activation)    (None, 8, 16, 1120)  0           BLOCK_4-1_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-1_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-1_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-1_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-1_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-1_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-1_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-1_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-1_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-1_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-1_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-1_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-1_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-1_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-2_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-2_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-2_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-2_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-2_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-2_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-2_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-2_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-2_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-2_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-2_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-2_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-2_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-2_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-2_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-2_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-1_BN_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-3_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-3_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-3_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-3_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-3_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-3_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-3_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-3_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-3_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-3_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-3_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-3_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-3_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-3_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-3_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-3_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-2_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_1 (Conv2D)       (None, 4, 8, 1120)   313600      BLOCK_4-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_1 (BatchNormalizat (None, 4, 8, 1120)   4480        BLOCK_4-4_CONV_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_1 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-4_BN_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_2 (DepthwiseConv (None, 4, 8, 1120)   10080       BLOCK_4-4_ACT_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_2_NOQUANT (BatchNo (None, 4, 8, 1120)   4480        BLOCK_4-4_CONV_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_2 (Activation)    (None, 4, 8, 1120)   0           BLOCK_4-4_BN_2_NOQUANT[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_AVG_POOL_1 (Global (None, 1120)         0           BLOCK_4-4_ACT_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_RESHAPE (Reshape)  (None, 1, 1, 1120)   0           BLOCK_4-4_SE_AVG_POOL_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_CONV_1 (Conv2D)    (None, 1, 1, 70)     78400       BLOCK_4-4_SE_RESHAPE[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_SE_CONV_2 (Conv2D)    (None, 1, 1, 1120)   78400       BLOCK_4-4_SE_CONV_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_MULTIPLY (Multiply)   (None, 4, 8, 1120)   0           BLOCK_4-4_ACT_2[0][0]            \n",
      "                                                                 BLOCK_4-4_SE_CONV_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ACT_QUANT (Activation (None, 4, 8, 1120)   0           BLOCK_4-4_MULTIPLY[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_CONV_3 (Conv2D)       (None, 4, 8, 280)    313600      BLOCK_4-4_ACT_QUANT[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_BN_3 (BatchNormalizat (None, 4, 8, 280)    1120        BLOCK_4-4_CONV_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "BLOCK_4-4_ADD (Add)             (None, 4, 8, 280)    0           BLOCK_4-4_BN_3[0][0]             \n",
      "                                                                 BLOCK_4-3_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BNORM_POST_NOQUANT (BatchNormal (None, 4, 8, 280)    1120        BLOCK_4-4_ADD[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ACT_POST (Activation)           (None, 4, 8, 280)    0           BNORM_POST_NOQUANT[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "POST_CONV_1 (Conv2D)            (None, 2, 6, 420)    1058400     ACT_POST[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "POST_BN_1 (BatchNormalization)  (None, 2, 6, 420)    1680        POST_CONV_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "POST_ACT_1 (Activation)         (None, 2, 6, 420)    0           POST_BN_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "GLOBAL_LME_POOL (GlobalLogExpPo (None, 420)          1           POST_ACT_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "CLASS_DENSE_1 (Dense)           (None, 2434)         1024714     GLOBAL_LME_POOL[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid_activation (Activation) (None, 2434)         0           CLASS_DENSE_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,604,470\n",
      "Trainable params: 7,564,848\n",
      "Non-trainable params: 39,622\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = model.layers[-1].output\n",
    "o = tf.keras.layers.Activation('sigmoid', name='sigmoid_activation')(x)\n",
    "\n",
    "model2 = Model(inputs=model.input, outputs=o)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d681b45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x1bf69867b88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_extended = model3\n",
    "model_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef22a857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNINGS 29\n",
      "Epoch 1/10\n",
      "RUNNINGS 29\n",
      "29/29 - 6s - loss: 0.6805 - accuracy: 0.9310 - false_negatives: 3.0000\n",
      "Epoch 2/10\n",
      "RUNNINGS 29\n",
      "29/29 - 6s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n",
      "Epoch 3/10\n",
      "RUNNINGS 29\n",
      "29/29 - 6s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n",
      "Epoch 4/10\n",
      "RUNNINGS 29\n",
      "29/29 - 6s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n",
      "Epoch 5/10\n",
      "RUNNINGS 29\n",
      "29/29 - 7s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n",
      "Epoch 6/10\n",
      "RUNNINGS 29\n",
      "29/29 - 7s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n",
      "Epoch 7/10\n",
      "RUNNINGS 29\n",
      "29/29 - 8s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n",
      "Epoch 8/10\n",
      "RUNNINGS 29\n",
      "29/29 - 7s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n",
      "Epoch 9/10\n",
      "RUNNINGS 29\n",
      "29/29 - 7s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n",
      "Epoch 10/10\n",
      "RUNNINGS 29\n",
      "29/29 - 6s - loss: 0.6552 - accuracy: 1.0000 - false_negatives: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, Flatten, ZeroPadding2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# microfaune training script\n",
    "\n",
    "if train:\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model_extended.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy', keras.metrics.FalseNegatives()])\n",
    "\n",
    "    alpha = 0.5\n",
    "    batch_size = 1\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    data_generator = DataGenerator(X_train, Y_train, batch_size)\n",
    "    \n",
    "    micro_callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                  patience=5, min_lr=1e-5),\n",
    "        #keras.callbacks.ModelCheckpoint('microfaune-' + date_str +'-{epoch:02d}.h5',\n",
    "        #                          save_weights_only=False)\n",
    "    ]\n",
    "    \n",
    "    #validation_data=(X_test, Y_test),\n",
    "    \n",
    "    history = model_extended.fit(data_generator, epochs=10,batch_size=1,\n",
    "                                  #validation_data=(X_test, Y_test), class_weight={0: alpha, 1: 1-alpha},callbacks=micro_callbacks,\n",
    "                                   verbose=2)\n",
    "    \n",
    "    #model.save(f\"model-{date_str}\")\n",
    "    #model.save_weights(f\"model_weights-{date_str}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66f5d5",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f22df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class ValidDataset(keras.utils.Sequence):\n",
    "    def __init__(self, X, Y, batch_size=32, output_size=10):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        #self.UIDs = UIDs\n",
    "        self.n = len(Y)\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        print(\"RUNNINGS\", int(np.floor(self.n)/self.batch_size))\n",
    "        return int(np.floor(self.n)/self.batch_size)\n",
    "    \n",
    "    def len_of_labels(self):\n",
    "        return self.output_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_inds = self.inds[self.batch_size*index:self.batch_size*(index+1)]\n",
    "        #print(batch_inds)\n",
    "        self.counter += self.batch_size\n",
    "        if self.counter >= self.n:\n",
    "            self.shuffle()\n",
    "            \n",
    "        #TODO: FIX SO BATCH IS MORE THAN 1\n",
    "        raw_labels = np.array([self.Y[batch_inds][0]])\n",
    "        formatted_labels = np.zeros(self.output_size)\n",
    "        formatted_labels[self.Y[batch_inds][0]] = 1\n",
    "        fprmatted_labels = np.array([formatted_labels])\n",
    "        #print(formatted_labels.shape)\n",
    "        #print(np.array([formatted_labels]).shape)\n",
    "        #print(self.X[batch_inds, ...][0].shape)\n",
    "        \n",
    "        #print(tf.convert_to_tensor(self.X[batch_inds, ...][0]), tf.convert_to_tensor(np.array([formatted_labels])))\n",
    "        return tf.convert_to_tensor(self.X[batch_inds, ...][0]), tf.convert_to_tensor(np.array([formatted_labels]))\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.inds = np.random.permutation(self.n)\n",
    "        self.counter = 0\n",
    "# if train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43acb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dataset = ValidDataset(X_train, Y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3d376c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_extended.predict(\n",
    "    validate_dataset.__getitem__(0)[0],\n",
    "    batch_size=None,\n",
    "    verbose='1',\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a8213f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "429e984c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float64, numpy=array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b33b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    " label_df = pd.DataFrame(columns=range(validate_dataset.len_of_labels()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6a7ac54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNINGS 29\n"
     ]
    }
   ],
   "source": [
    "#Label_df_one_hot_encoding\n",
    "label_df = pd.DataFrame(columns=range(validate_dataset.len_of_labels()))\n",
    "scores_df = pd.DataFrame(columns=range(validate_dataset.len_of_labels()))\n",
    "preds_df = pd.DataFrame(columns=range(validate_dataset.len_of_labels()))\n",
    "for i in range(len(validate_dataset)):\n",
    "    #print(i)\n",
    "    predictions = model_extended.predict(\n",
    "        validate_dataset.__getitem__(i)[0],\n",
    "        batch_size=None,\n",
    "        verbose='1',\n",
    "        steps=None,\n",
    "        callbacks=None,\n",
    "        max_queue_size=10,\n",
    "        workers=1,\n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    \n",
    "    label = predictions.argmax()\n",
    "    label_arr = np.zeros(validate_dataset.len_of_labels())\n",
    "    label_arr[label] = 1\n",
    "    \n",
    "    preds_df = preds_df.append(pd.DataFrame(np.array([label_arr])))\n",
    "    scores_df = scores_df.append(pd.DataFrame(predictions))\n",
    "    label_df = label_df.append(pd.DataFrame(validate_dataset.__getitem__(i)[1].numpy()))\n",
    "    \n",
    "preds_df.columns = species_of_interests\n",
    "scores_df.columns = species_of_interests\n",
    "label_df.columns = species_of_interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "895d6291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celeus grammicus</th>\n",
       "      <th>Microcerculus marginatus</th>\n",
       "      <th>Myioborus miniatus</th>\n",
       "      <th>Ramphastos tucanus</th>\n",
       "      <th>Thraupis episcopus</th>\n",
       "      <th>Tolmomyias sulphurescens</th>\n",
       "      <th>Trogon viridis</th>\n",
       "      <th>Turdus leucomelas</th>\n",
       "      <th>Xiphorhynchus guttatus</th>\n",
       "      <th>Zonotrichia capensis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Celeus grammicus  Microcerculus marginatus  Myioborus miniatus  \\\n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "\n",
       "   Ramphastos tucanus  Thraupis episcopus  Tolmomyias sulphurescens  \\\n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "\n",
       "   Trogon viridis  Turdus leucomelas  Xiphorhynchus guttatus  \\\n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "\n",
       "   Zonotrichia capensis  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "196f4572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celeus grammicus</th>\n",
       "      <th>Microcerculus marginatus</th>\n",
       "      <th>Myioborus miniatus</th>\n",
       "      <th>Ramphastos tucanus</th>\n",
       "      <th>Thraupis episcopus</th>\n",
       "      <th>Tolmomyias sulphurescens</th>\n",
       "      <th>Trogon viridis</th>\n",
       "      <th>Turdus leucomelas</th>\n",
       "      <th>Xiphorhynchus guttatus</th>\n",
       "      <th>Zonotrichia capensis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.104210e-04</td>\n",
       "      <td>3.560349e-05</td>\n",
       "      <td>2.213924e-05</td>\n",
       "      <td>8.187241e-06</td>\n",
       "      <td>1.944005e-04</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>6.468157e-05</td>\n",
       "      <td>5.166131e-06</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1.056776e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.627651e-07</td>\n",
       "      <td>4.345748e-06</td>\n",
       "      <td>8.815441e-06</td>\n",
       "      <td>2.690968e-05</td>\n",
       "      <td>6.165387e-05</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>2.557536e-07</td>\n",
       "      <td>9.391765e-05</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>1.894329e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.799517e-08</td>\n",
       "      <td>1.508930e-05</td>\n",
       "      <td>1.102624e-05</td>\n",
       "      <td>2.701115e-06</td>\n",
       "      <td>3.923478e-06</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>4.328131e-07</td>\n",
       "      <td>1.251179e-05</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.413498e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.424775e-07</td>\n",
       "      <td>1.209882e-05</td>\n",
       "      <td>2.305877e-05</td>\n",
       "      <td>1.074534e-05</td>\n",
       "      <td>1.976490e-04</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>2.281185e-05</td>\n",
       "      <td>1.737759e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.898553e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.593954e-07</td>\n",
       "      <td>1.461951e-06</td>\n",
       "      <td>4.737427e-06</td>\n",
       "      <td>1.030966e-05</td>\n",
       "      <td>9.012479e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.038857e-07</td>\n",
       "      <td>2.086665e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>3.207815e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.437206e-06</td>\n",
       "      <td>1.207849e-05</td>\n",
       "      <td>9.276489e-05</td>\n",
       "      <td>4.856948e-05</td>\n",
       "      <td>2.194928e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.296203e-06</td>\n",
       "      <td>4.064318e-05</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1.773160e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.139142e-08</td>\n",
       "      <td>5.009472e-04</td>\n",
       "      <td>1.876264e-05</td>\n",
       "      <td>1.803797e-06</td>\n",
       "      <td>3.357947e-05</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>2.925395e-05</td>\n",
       "      <td>7.518472e-05</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.842108e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.170669e-04</td>\n",
       "      <td>3.194386e-06</td>\n",
       "      <td>7.793538e-06</td>\n",
       "      <td>1.105288e-05</td>\n",
       "      <td>5.570335e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.713189e-07</td>\n",
       "      <td>2.886933e-06</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>9.542638e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.121773e-05</td>\n",
       "      <td>1.081588e-07</td>\n",
       "      <td>4.496237e-05</td>\n",
       "      <td>5.155352e-08</td>\n",
       "      <td>1.322420e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.387429e-07</td>\n",
       "      <td>3.763822e-07</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>1.672588e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.408051e-07</td>\n",
       "      <td>2.881122e-06</td>\n",
       "      <td>3.614186e-07</td>\n",
       "      <td>4.250903e-05</td>\n",
       "      <td>9.665576e-06</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>7.228243e-09</td>\n",
       "      <td>6.210793e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.574632e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.657442e-06</td>\n",
       "      <td>1.844204e-06</td>\n",
       "      <td>1.133900e-04</td>\n",
       "      <td>2.940162e-05</td>\n",
       "      <td>2.427101e-04</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.243567e-05</td>\n",
       "      <td>1.537444e-06</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>4.970779e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.165330e-07</td>\n",
       "      <td>9.714132e-07</td>\n",
       "      <td>1.469886e-05</td>\n",
       "      <td>2.950991e-07</td>\n",
       "      <td>2.385829e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.245984e-06</td>\n",
       "      <td>6.401980e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.140847e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.593954e-07</td>\n",
       "      <td>1.461951e-06</td>\n",
       "      <td>4.737427e-06</td>\n",
       "      <td>1.030966e-05</td>\n",
       "      <td>9.012479e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.038857e-07</td>\n",
       "      <td>2.086665e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>3.207815e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.514841e-06</td>\n",
       "      <td>2.593962e-07</td>\n",
       "      <td>1.679727e-05</td>\n",
       "      <td>5.689642e-06</td>\n",
       "      <td>1.325045e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.386588e-08</td>\n",
       "      <td>4.550448e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.582611e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.595767e-06</td>\n",
       "      <td>2.801675e-07</td>\n",
       "      <td>1.689196e-04</td>\n",
       "      <td>1.608689e-06</td>\n",
       "      <td>2.513230e-04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.528229e-05</td>\n",
       "      <td>8.882549e-06</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.996639e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.656432e-06</td>\n",
       "      <td>2.004910e-06</td>\n",
       "      <td>1.906358e-06</td>\n",
       "      <td>9.015874e-06</td>\n",
       "      <td>9.044832e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.059989e-08</td>\n",
       "      <td>7.183726e-07</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>4.543248e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.036672e-07</td>\n",
       "      <td>3.880853e-06</td>\n",
       "      <td>4.539547e-05</td>\n",
       "      <td>1.987401e-06</td>\n",
       "      <td>6.557002e-05</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>3.698828e-05</td>\n",
       "      <td>2.170205e-04</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>9.780551e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.408051e-07</td>\n",
       "      <td>2.881122e-06</td>\n",
       "      <td>3.614186e-07</td>\n",
       "      <td>4.250903e-05</td>\n",
       "      <td>9.665576e-06</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>7.228243e-09</td>\n",
       "      <td>6.210793e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.574632e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.657442e-06</td>\n",
       "      <td>1.844204e-06</td>\n",
       "      <td>1.133900e-04</td>\n",
       "      <td>2.940162e-05</td>\n",
       "      <td>2.427101e-04</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.243567e-05</td>\n",
       "      <td>1.537444e-06</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>4.970779e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.799517e-08</td>\n",
       "      <td>1.508930e-05</td>\n",
       "      <td>1.102624e-05</td>\n",
       "      <td>2.701115e-06</td>\n",
       "      <td>3.923478e-06</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>4.328131e-07</td>\n",
       "      <td>1.251179e-05</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.413498e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.104152e-05</td>\n",
       "      <td>6.830172e-05</td>\n",
       "      <td>9.681000e-06</td>\n",
       "      <td>4.562411e-05</td>\n",
       "      <td>1.781285e-04</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>1.257956e-04</td>\n",
       "      <td>5.531609e-04</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>1.259446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.139142e-08</td>\n",
       "      <td>5.009472e-04</td>\n",
       "      <td>1.876264e-05</td>\n",
       "      <td>1.803797e-06</td>\n",
       "      <td>3.357947e-05</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>2.925395e-05</td>\n",
       "      <td>7.518472e-05</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.842108e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.854384e-07</td>\n",
       "      <td>1.797200e-06</td>\n",
       "      <td>1.329184e-04</td>\n",
       "      <td>1.065877e-06</td>\n",
       "      <td>3.524512e-03</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>1.626810e-05</td>\n",
       "      <td>1.484596e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.131735e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.007013e-07</td>\n",
       "      <td>4.509504e-06</td>\n",
       "      <td>3.196312e-06</td>\n",
       "      <td>2.911381e-05</td>\n",
       "      <td>2.396473e-05</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>2.763388e-06</td>\n",
       "      <td>3.780127e-04</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.366824e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.772920e-06</td>\n",
       "      <td>1.089549e-06</td>\n",
       "      <td>1.500573e-05</td>\n",
       "      <td>9.827267e-06</td>\n",
       "      <td>3.499013e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.002357e-04</td>\n",
       "      <td>1.079891e-06</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>5.258484e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.104152e-05</td>\n",
       "      <td>6.830172e-05</td>\n",
       "      <td>9.681000e-06</td>\n",
       "      <td>4.562411e-05</td>\n",
       "      <td>1.781285e-04</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>1.257956e-04</td>\n",
       "      <td>5.531609e-04</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>1.259446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.854384e-07</td>\n",
       "      <td>1.797200e-06</td>\n",
       "      <td>1.329184e-04</td>\n",
       "      <td>1.065877e-06</td>\n",
       "      <td>3.524512e-03</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>1.626810e-05</td>\n",
       "      <td>1.484596e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.131735e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.139142e-08</td>\n",
       "      <td>5.009472e-04</td>\n",
       "      <td>1.876264e-05</td>\n",
       "      <td>1.803797e-06</td>\n",
       "      <td>3.357947e-05</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>2.925395e-05</td>\n",
       "      <td>7.518472e-05</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.842108e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.064573e-04</td>\n",
       "      <td>3.756698e-06</td>\n",
       "      <td>3.169971e-06</td>\n",
       "      <td>2.197446e-07</td>\n",
       "      <td>1.596808e-04</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>9.906086e-07</td>\n",
       "      <td>7.970292e-05</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>1.407645e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Celeus grammicus  Microcerculus marginatus  Myioborus miniatus  \\\n",
       "0      3.104210e-04              3.560349e-05        2.213924e-05   \n",
       "0      8.627651e-07              4.345748e-06        8.815441e-06   \n",
       "0      9.799517e-08              1.508930e-05        1.102624e-05   \n",
       "0      1.424775e-07              1.209882e-05        2.305877e-05   \n",
       "0      2.593954e-07              1.461951e-06        4.737427e-06   \n",
       "0      3.437206e-06              1.207849e-05        9.276489e-05   \n",
       "0      1.139142e-08              5.009472e-04        1.876264e-05   \n",
       "0      3.170669e-04              3.194386e-06        7.793538e-06   \n",
       "0      1.121773e-05              1.081588e-07        4.496237e-05   \n",
       "0      8.408051e-07              2.881122e-06        3.614186e-07   \n",
       "0      1.657442e-06              1.844204e-06        1.133900e-04   \n",
       "0      5.165330e-07              9.714132e-07        1.469886e-05   \n",
       "0      2.593954e-07              1.461951e-06        4.737427e-06   \n",
       "0      2.514841e-06              2.593962e-07        1.679727e-05   \n",
       "0      3.595767e-06              2.801675e-07        1.689196e-04   \n",
       "0      7.656432e-06              2.004910e-06        1.906358e-06   \n",
       "0      2.036672e-07              3.880853e-06        4.539547e-05   \n",
       "0      8.408051e-07              2.881122e-06        3.614186e-07   \n",
       "0      1.657442e-06              1.844204e-06        1.133900e-04   \n",
       "0      9.799517e-08              1.508930e-05        1.102624e-05   \n",
       "0      1.104152e-05              6.830172e-05        9.681000e-06   \n",
       "0      1.139142e-08              5.009472e-04        1.876264e-05   \n",
       "0      2.854384e-07              1.797200e-06        1.329184e-04   \n",
       "0      8.007013e-07              4.509504e-06        3.196312e-06   \n",
       "0      1.772920e-06              1.089549e-06        1.500573e-05   \n",
       "0      1.104152e-05              6.830172e-05        9.681000e-06   \n",
       "0      2.854384e-07              1.797200e-06        1.329184e-04   \n",
       "0      1.139142e-08              5.009472e-04        1.876264e-05   \n",
       "0      3.064573e-04              3.756698e-06        3.169971e-06   \n",
       "\n",
       "   Ramphastos tucanus  Thraupis episcopus  Tolmomyias sulphurescens  \\\n",
       "0        8.187241e-06        1.944005e-04                  0.999999   \n",
       "0        2.690968e-05        6.165387e-05                  0.999984   \n",
       "0        2.701115e-06        3.923478e-06                  0.999959   \n",
       "0        1.074534e-05        1.976490e-04                  0.999995   \n",
       "0        1.030966e-05        9.012479e-06                  1.000000   \n",
       "0        4.856948e-05        2.194928e-05                  1.000000   \n",
       "0        1.803797e-06        3.357947e-05                  0.999993   \n",
       "0        1.105288e-05        5.570335e-05                  1.000000   \n",
       "0        5.155352e-08        1.322420e-06                  1.000000   \n",
       "0        4.250903e-05        9.665576e-06                  0.999939   \n",
       "0        2.940162e-05        2.427101e-04                  0.999999   \n",
       "0        2.950991e-07        2.385829e-06                  1.000000   \n",
       "0        1.030966e-05        9.012479e-06                  1.000000   \n",
       "0        5.689642e-06        1.325045e-06                  1.000000   \n",
       "0        1.608689e-06        2.513230e-04                  1.000000   \n",
       "0        9.015874e-06        9.044832e-07                  1.000000   \n",
       "0        1.987401e-06        6.557002e-05                  0.999993   \n",
       "0        4.250903e-05        9.665576e-06                  0.999939   \n",
       "0        2.940162e-05        2.427101e-04                  0.999999   \n",
       "0        2.701115e-06        3.923478e-06                  0.999959   \n",
       "0        4.562411e-05        1.781285e-04                  0.999992   \n",
       "0        1.803797e-06        3.357947e-05                  0.999993   \n",
       "0        1.065877e-06        3.524512e-03                  0.999988   \n",
       "0        2.911381e-05        2.396473e-05                  0.999978   \n",
       "0        9.827267e-06        3.499013e-05                  1.000000   \n",
       "0        4.562411e-05        1.781285e-04                  0.999992   \n",
       "0        1.065877e-06        3.524512e-03                  0.999988   \n",
       "0        1.803797e-06        3.357947e-05                  0.999993   \n",
       "0        2.197446e-07        1.596808e-04                  0.999966   \n",
       "\n",
       "   Trogon viridis  Turdus leucomelas  Xiphorhynchus guttatus  \\\n",
       "0    6.468157e-05       5.166131e-06                0.000072   \n",
       "0    2.557536e-07       9.391765e-05                0.000094   \n",
       "0    4.328131e-07       1.251179e-05                0.000025   \n",
       "0    2.281185e-05       1.737759e-05                0.000005   \n",
       "0    2.038857e-07       2.086665e-07                0.000019   \n",
       "0    1.296203e-06       4.064318e-05                0.000063   \n",
       "0    2.925395e-05       7.518472e-05                0.000176   \n",
       "0    4.713189e-07       2.886933e-06                0.000242   \n",
       "0    8.387429e-07       3.763822e-07                0.000084   \n",
       "0    7.228243e-09       6.210793e-07                0.000003   \n",
       "0    1.243567e-05       1.537444e-06                0.000230   \n",
       "0    1.245984e-06       6.401980e-06                0.000004   \n",
       "0    2.038857e-07       2.086665e-07                0.000019   \n",
       "0    6.386588e-08       4.550448e-07                0.000015   \n",
       "0    1.528229e-05       8.882549e-06                0.000035   \n",
       "0    5.059989e-08       7.183726e-07                0.000026   \n",
       "0    3.698828e-05       2.170205e-04                0.001276   \n",
       "0    7.228243e-09       6.210793e-07                0.000003   \n",
       "0    1.243567e-05       1.537444e-06                0.000230   \n",
       "0    4.328131e-07       1.251179e-05                0.000025   \n",
       "0    1.257956e-04       5.531609e-04                0.001736   \n",
       "0    2.925395e-05       7.518472e-05                0.000176   \n",
       "0    1.626810e-05       1.484596e-05                0.000003   \n",
       "0    2.763388e-06       3.780127e-04                0.000033   \n",
       "0    1.002357e-04       1.079891e-06                0.000706   \n",
       "0    1.257956e-04       5.531609e-04                0.001736   \n",
       "0    1.626810e-05       1.484596e-05                0.000003   \n",
       "0    2.925395e-05       7.518472e-05                0.000176   \n",
       "0    9.906086e-07       7.970292e-05                0.000090   \n",
       "\n",
       "   Zonotrichia capensis  \n",
       "0          1.056776e-04  \n",
       "0          1.894329e-05  \n",
       "0          8.413498e-05  \n",
       "0          2.898553e-06  \n",
       "0          3.207815e-06  \n",
       "0          1.773160e-06  \n",
       "0          5.842108e-06  \n",
       "0          9.542638e-07  \n",
       "0          1.672588e-05  \n",
       "0          1.574632e-05  \n",
       "0          4.970779e-06  \n",
       "0          9.140847e-06  \n",
       "0          3.207815e-06  \n",
       "0          1.582611e-05  \n",
       "0          1.996639e-06  \n",
       "0          4.543248e-06  \n",
       "0          9.780551e-05  \n",
       "0          1.574632e-05  \n",
       "0          4.970779e-06  \n",
       "0          8.413498e-05  \n",
       "0          1.259446e-04  \n",
       "0          5.842108e-06  \n",
       "0          1.131735e-05  \n",
       "0          1.366824e-05  \n",
       "0          5.258484e-05  \n",
       "0          1.259446e-04  \n",
       "0          1.131735e-05  \n",
       "0          5.842108e-06  \n",
       "0          1.407645e-05  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "21ab5943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celeus grammicus</th>\n",
       "      <th>Microcerculus marginatus</th>\n",
       "      <th>Myioborus miniatus</th>\n",
       "      <th>Ramphastos tucanus</th>\n",
       "      <th>Thraupis episcopus</th>\n",
       "      <th>Tolmomyias sulphurescens</th>\n",
       "      <th>Trogon viridis</th>\n",
       "      <th>Turdus leucomelas</th>\n",
       "      <th>Xiphorhynchus guttatus</th>\n",
       "      <th>Zonotrichia capensis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Celeus grammicus  Microcerculus marginatus  Myioborus miniatus  \\\n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "0               0.0                       0.0                 0.0   \n",
       "\n",
       "   Ramphastos tucanus  Thraupis episcopus  Tolmomyias sulphurescens  \\\n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "0                 0.0                 0.0                       1.0   \n",
       "\n",
       "   Trogon viridis  Turdus leucomelas  Xiphorhynchus guttatus  \\\n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "0             0.0                0.0                     0.0   \n",
       "\n",
       "   Zonotrichia capensis  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  \n",
       "0                   0.0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9ae42ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "48bb5fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       1.00      1.00      1.00        29\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        29\n",
      "   macro avg       0.10      0.10      0.10        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      " samples avg       1.00      1.00      1.00        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_df, preds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3bb96c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for species in species_of_interests:\n",
    "    fpr, tpr, thresh = roc_curve(label_df[species],  scores_df[species])\n",
    "    auc = roc_auc_score(label_df[species],  preds_df[species])\n",
    "    plt.plot(fpr,tpr,label=\"AUC \" + species + \" \"+str(auc))\n",
    "\n",
    "plt.title('Classwise ROC Curves')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f98b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490b3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
