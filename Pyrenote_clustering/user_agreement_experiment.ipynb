{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.cluster import DBSCAN\n",
    "import math\n",
    "import statistics\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import itertools\n",
    "\n",
    "#Convert CSV to Dataframe\n",
    "data = pd.read_csv(\"C:/Users/Siloux/Downloads/pairwise_user_experiment (5).csv\", header=[0])\n",
    "data[\"FOLDER\"] = data[\"IN FILE\"].apply(lambda x: \"\")\n",
    "data[\"LAST MOD BY\"] = data[\"LAST MOD BY\"].apply(lambda x: x.split(\" \")[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a4ef3",
   "metadata": {},
   "source": [
    "#### Import Confidence Functions and Create List of Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896df0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function confidence_functions.confidence.get_pairwise_iou(df, users)>,\n",
       " <function confidence_functions.confidence.get_silhoutte_confidence(df, users)>,\n",
       " <function confidence_functions.confidence.get_silhoutte_users_confidence(df, users)>,\n",
       " <function confidence_functions.confidence.majority_vote(df, users, chunk_length=1)>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confidence_functions.confidence import *\n",
    " \n",
    "confidence_funcs = [get_pairwise_iou, get_silhoutte_confidence, get_silhoutte_users_confidence, majority_vote]\n",
    "confidence_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142d12d",
   "metadata": {},
   "source": [
    "### permuatation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd496755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def permutate_users(df, num_users, clip_name, confidence_func):\n",
    "    #Get data for indivual clip\n",
    "    results = []\n",
    "    df = df[df[\"IN FILE\"] == clip_name]\n",
    "    users = df[\"LAST MOD BY\"].unique()\n",
    "    \n",
    "    #For each insertion order, get the confidence via some confidence function\n",
    "    for user_permutation in itertools.permutations(users, num_users):\n",
    "        results.append(confidence_func(df, user_permutation))\n",
    "        \n",
    "    results = np.mean(results)\n",
    "    return results\n",
    "    \n",
    "#permutate_users(data, 2, \"XC425555_-_Screaming_Piha_-_Lipaugus_vociferans.mp3\", get_silhoutte_users_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e6675",
   "metadata": {},
   "source": [
    "### Clip Spefific Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830578aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_confidence_by_clip(df, clip_name, confidence_funcs):\n",
    "    results = {}\n",
    "    df = df[df[\"IN FILE\"] == clip_name]\n",
    "    users = df[\"LAST MOD BY\"].unique()\n",
    "    for confidence_func in confidence_funcs:\n",
    "        print(\"working with function: \" + confidence_func.__name__)\n",
    "        results[confidence_func] = {}\n",
    "        \n",
    "        for user_count in range(len(users)):\n",
    "            results[confidence_func][user_count+1]= permutate_users(df, user_count+1, clip_name, confidence_func)\n",
    "    return results\n",
    "\n",
    "def determine_confidence_by_func(df, confidence_funcs):\n",
    "    results = {}\n",
    "    users = df[\"LAST MOD BY\"].unique()\n",
    "    files = df[\"IN FILE\"].unique()\n",
    "    for func in confidence_funcs:\n",
    "        results[func] = {}\n",
    "        for user_count in range(len(users)):\n",
    "            confidence = np.array([])\n",
    "            for file in files:\n",
    "                if (user_count < len(df[df[\"IN FILE\"] == file][\"LAST MOD BY\"].unique())):\n",
    "                       confidence = np.append(confidence, permutate_users(df, user_count+1, file, func))\n",
    "            print(confidence)\n",
    "            confidence = confidence.mean()\n",
    "            results[func][user_count+1] = confidence\n",
    "    return results\n",
    "        \n",
    "#determine_confidence_by_clip(data, \"XC425555_-_Screaming_Piha_-_Lipaugus_vociferans.mp3\", confidence_funcs)\n",
    "#determine_confidence_by_func(data, confidence_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24888e17",
   "metadata": {},
   "source": [
    "# Full Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with file: XC425555_-_Screaming_Piha_-_Lipaugus_vociferans.mp3\n",
      "working with function: get_pairwise_iou\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanh\\Desktop\\e4e\\passive-acoustic-biodiversity\\Pyrenote_clustering\\confidence_functions\\confidence.py:32: RuntimeWarning: Mean of empty slice.\n",
      "  iou_scores = iou_scores.mean()\n",
      "C:\\ProgramData\\Miniconda3\\envs\\species-id\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(df, confidence_funcs):\n",
    "    #Get the adverage confidence over number of users for each file\n",
    "    results = {\"by_clip\": {}, \"Over_all_clips\": {}}\n",
    "    filenames = df[\"IN FILE\"].unique()\n",
    "    for file in filenames:\n",
    "        print(\"working with file: \" + file)\n",
    "        results[\"by_clip\"][file] = determine_confidence_by_clip(df, file, confidence_funcs)\n",
    "    \n",
    "    print(\"Get adverage over all files\")\n",
    "    results[\"Over_all_clips\"] = determine_confidence_by_func(df, confidence_funcs)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return results\n",
    "\n",
    "experiment_results = run_experiment(data, confidence_funcs)\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0aa0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_graph(experiment_results):\n",
    "    for filename in experiment_results:\n",
    "        #For each filename, plot the performance of each confidence function\n",
    "        for confidence_func in experiment_results[filename]:\n",
    "            confidence_dirc = experiment_results[filename][confidence_func]\n",
    "            users_count = list(confidence_dirc.keys())\n",
    "            score = list(confidence_dirc.values())\n",
    "            plt.plot(users_count, score, label=(confidence_func.__name__))\n",
    "        \n",
    "        #Throw in some fancy formatting\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(filename)\n",
    "        plt.xlabel(\"User Count\")\n",
    "        plt.ylabel(\"Average Confidence of Function\")\n",
    "        plt.show()\n",
    "\n",
    "generate_graph(experiment_results[\"by_clip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5034f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph_all(experiment_results):\n",
    "    #For each filename, plot the performance of each confidence function\n",
    "    for confidence_func in experiment_results:\n",
    "        confidence_dirc = experiment_results[confidence_func]\n",
    "        users_count = list(confidence_dirc.keys())\n",
    "        score = list(confidence_dirc.values())\n",
    "        plt.plot(users_count, score, label=(confidence_func.__name__))\n",
    "\n",
    "    #Throw in some fancy formatting\n",
    "    plt.legend(loc='best')\n",
    "    #plt.title(filename)\n",
    "    plt.xlabel(\"User Count\")\n",
    "    plt.ylabel(\"Average Confidence of Function\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "generate_graph_all(experiment_results[\"Over_all_clips\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
