{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f549812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from network import TweetyNet\n",
    "import librosa\n",
    "from librosa import display\n",
    "from microfaune.audio import wav2spc, create_spec, load_wav\n",
    "from glob import glob\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from CustomAudioDataset import CustomAudioDataset\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "855e9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to find correct dimensions for model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5762e73",
   "metadata": {},
   "source": [
    "Data to look at \n",
    "total: look at number of each label (normalized)\n",
    "across birds: Look at number of each label (normalized)\n",
    "              Look at lengths of videos (in seconds\n",
    "              Look at length of folder (number of vids and length of all videos in folder in sec)\n",
    "              per clip statistics\n",
    "Across videos in a bird: Look at label distribution, average length and other statistics. \n",
    "per segment statistics available too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e96d5291",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dump = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6506f073",
   "metadata": {},
   "source": [
    "# Todo:\n",
    "## Setup train and test and validation set.\n",
    "Randomly split the data (train) 900 and (test) 400 seconds.\n",
    "Implement stratified split. \n",
    "Also need to be able to control the training set length in seconds\n",
    "## Training\n",
    "train 10 models with training set. \n",
    "train on randomly drawn subset of the data. \n",
    "## Evaluation\n",
    "means we can have a validation set. \n",
    "calculate frame error and syllable error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64911a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path, bird_name, use_dump=True):\n",
    "    mel_dump_file = os.path.join(data_path, bird_name, \"mel_dataset.pkl\")\n",
    "    if os.path.exists(mel_dump_file) and use_dump:\n",
    "        with open(mel_dump_file, \"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "    else:\n",
    "        print(\"FAILED\")\n",
    "        dataset = compute_bird_features(os.path.join(data_path, bird_name))\n",
    "        with open(mel_dump_file, \"wb\") as f:\n",
    "            pickle.dump(dataset, f)\n",
    "    inds = [i for i, x in enumerate(dataset[\"X\"])]\n",
    "    X = np.array([dataset[\"X\"][i].transpose() for i in inds])\n",
    "    Y = np.array([dataset[\"Y\"][i] for i in inds])\n",
    "    uids = np.array([dataset[\"uids\"][i] for i in inds])\n",
    "    return X, Y, uids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "656e8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We actually need to split the data to 900 seconds and 400 seconds. -> 9/13, 4/13 then get a random subset of the data\n",
    "def split_dataset(X, Y, test_size, random_state=0):\n",
    "    split_generator = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    ind_train, ind_test = next(split_generator.split(X, Y))\n",
    "    X_train, X_test = X[ind_train, :, :], X[ind_test, :, :]\n",
    "    Y_train, Y_test = Y[ind_train], Y[ind_test]\n",
    "    return ind_train, ind_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "685b6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/mugetronblue/E4E/AcousticSpecies/passive-acoustic-biodiversity/TweetyNET/data/BirdSong_Recognition/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7388ea1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94,) (94,) (94,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mugetronblue/opt/anaconda3/envs/species-id/lib/python3.7/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  if sys.path[0] == '':\n",
      "/Users/mugetronblue/opt/anaconda3/envs/species-id/lib/python3.7/site-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  del sys.path[0]\n",
      "/Users/mugetronblue/opt/anaconda3/envs/species-id/lib/python3.7/site-packages/ipykernel_launcher.py:2: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \n",
      "/Users/mugetronblue/opt/anaconda3/envs/species-id/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X, Y, uids = load_dataset(data_dir, \"Bird10\", use_dump=True)\n",
    "X = np.array([x.astype(np.float32)/255 for x in X])\n",
    "uids = uids\n",
    "\n",
    "print(X.shape, Y.shape, uids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d4cb29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train, X_test= X[ind_train, :, :, np.newaxis], X[ind_test, :, :, np.newaxis]\\nY_train, Y_test= Y[ind_train], Y[ind_test]\\nuids_train, uids_test = uids[ind_train], uids[ind_test]\\nstarts_train, starts_test = starts[ind_train], starts[ind_test]\\nends_train, ends_test = ends[ind_train], ends[ind_test]\\n# Split the ind_test to get a validation set. \\nind_test, ind_val = split_dataset(X_test, Y_test, .30)\\nX_test, X_val = X[ind_test, :, :, np.newaxis], X[ind_val, :, :, np.newaxis]\\nY_test, Y_val = Y[ind_test], Y[ind_val]\\nuids_test, uids_val = uids[ind_test], uids[ind_val]\\nstarts_test, starts_val = starts[ind_train], starts[ind_test]\\nends_train, ends_test = ends[ind_train], ends[ind_test]\\ndel X, Y\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to control the length in seconds. \n",
    "\n",
    "#Stratified split\n",
    "#ind_train, ind_test = split_dataset(X, Y, 0.308)\n",
    "# rework some of this. look up how to convert the duration and start to seconds to get accurate times. \n",
    "# we need frames and frame rate in order to get duration. -> we can calculate this after the fact. \n",
    "# do in morning. \n",
    "# duration = frames / float(rate)\n",
    "# Random sample of training data 90% use remaining to add to validation set. \n",
    "#ind_train = random.choice(ind_train, size=len(ind_train)*0.9, replace=False)\n",
    "\"\"\"\n",
    "X_train, X_test= X[ind_train, :, :, np.newaxis], X[ind_test, :, :, np.newaxis]\n",
    "Y_train, Y_test= Y[ind_train], Y[ind_test]\n",
    "uids_train, uids_test = uids[ind_train], uids[ind_test]\n",
    "starts_train, starts_test = starts[ind_train], starts[ind_test]\n",
    "ends_train, ends_test = ends[ind_train], ends[ind_test]\n",
    "# Split the ind_test to get a validation set. \n",
    "ind_test, ind_val = split_dataset(X_test, Y_test, .30)\n",
    "X_test, X_val = X[ind_test, :, :, np.newaxis], X[ind_val, :, :, np.newaxis]\n",
    "Y_test, Y_val = Y[ind_test], Y[ind_val]\n",
    "uids_test, uids_val = uids[ind_test], uids[ind_val]\n",
    "starts_test, starts_val = starts[ind_train], starts[ind_test]\n",
    "ends_train, ends_test = ends[ind_train], ends[ind_test]\n",
    "del X, Y\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f29dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Training set: \", Counter(Y_train))\n",
    "#print(\"Test set: \", Counter(Y_test))\n",
    "#print(\"Val set: \", Counter(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "497590c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(path=None, data=None, sr=None):\n",
    "    if path != None:\n",
    "        y, _sr = librosa.load(path)\n",
    "    elif data != None:\n",
    "        y = data\n",
    "        _sr = sr\n",
    "    else:\n",
    "        Print(\"Usage: specify a path or the data.\")\n",
    "        return 0\n",
    "    frames = [len(y)]\n",
    "    return librosa.frames_to_time(frames, _sr, 1)\n",
    "def get_bird_time(path, bird_num):\n",
    "    # let's store all this info in a csv and push it to the server.\n",
    "    the_path = os.path.join(data_dir, bird_num, \"Wave\")\n",
    "    all_time = 0\n",
    "    times = {\"file\": [], \"time\" : []}\n",
    "    mel_dump_file = os.path.join(data_dir, bird_num, \"time_dataset.pkl\")\n",
    "    if os.path.exists(mel_dump_file) and use_dump:\n",
    "        with open(mel_dump_file, \"rb\") as f:\n",
    "            times = pickle.load(f)\n",
    "            all_time = times[\"time\"][-1]\n",
    "    else:\n",
    "        files = os.listdir(the_path)\n",
    "        for f in files:\n",
    "            tim = get_time(os.path.join(the_path, f))\n",
    "            all_time += tim\n",
    "            times['file'].append(f)\n",
    "            times['time'].append(tim)\n",
    "        times['file'].append(bird_num)\n",
    "        times['time'].append(all_time)\n",
    "        with open(mel_dump_file, \"wb\") as f:\n",
    "            pickle.dump(times, f)\n",
    "    return all_time, times\n",
    "#Use this function in order to break the dataset apart. into 900 seconds for training and 400 for testing. \n",
    "# any leftover can be put into validation ~400 seconds \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "667c80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dataset = get_bird_time(data_dir, \"Bird10\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21a0f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a in range(0, 11):\n",
    "#    get_bird_time(data_dir, \"Bird\"+str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "579c74e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ee6eb87d6b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bre' is not defined"
     ]
    }
   ],
   "source": [
    "bre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f379488d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.415011337868481"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dataset[\"time\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26121d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,11):\n",
    "#    get_bird_time(data_dir, \"Bird\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfcc1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function randomly select files to put in training and test set. \n",
    "#return filesnames for test and train\n",
    "# in order to stratify we will need to know all the labels in an audio recording\n",
    "# just on time\n",
    "def split_data(X, Y, uids, time_dataset, train_size = 900, test_size = 400):\n",
    "    test = {'X' : [], 'Y' : [], 'uids' :[]}\n",
    "    train = {'X' : [], 'Y' : [], 'uids' :[]}\n",
    "    val = {'X' : [], 'Y' : [], 'uids' :[]}\n",
    "    #actually split it up now. then look at class distribution among classes. \n",
    "    #labels = tag_videos(Y, uids, time_dataset)\n",
    "    train_names, test_names, val_names = split_time(time_dataset, train_size, test_size)\n",
    "    for i, f in enumerate(uids):\n",
    "        if f in train_names:\n",
    "            train[\"X\"].append(X[i])\n",
    "            train[\"Y\"].append(Y[i])\n",
    "            train[\"uids\"].append(uids[i])\n",
    "            \n",
    "        elif f in test_names:\n",
    "            test[\"X\"].append(X[i])\n",
    "            test[\"Y\"].append(Y[i])\n",
    "            test[\"uids\"].append(uids[i])\n",
    "            \n",
    "        if f in val_names:\n",
    "            val[\"X\"].append(X[i])\n",
    "            val[\"Y\"].append(Y[i])\n",
    "            val[\"uids\"].append(uids[i])\n",
    "            \n",
    "    return train, test, val\n",
    "            \n",
    "    \n",
    "    \n",
    "def split_time(time_dataset, train_size, test_size):\n",
    "    train = set()\n",
    "    val = set()\n",
    "    test = set()\n",
    "    seen = set()\n",
    "    train_amt = 0\n",
    "    test_amt = 0\n",
    "    val_amt = 0\n",
    "    dataset = {'file' : time_dataset['file'][:-1], 'time' : time_dataset['time'][:-1]}\n",
    "    val_seen = False\n",
    "    #print(time_dataset['time'][-1])\n",
    "    while ((train_amt + test_amt + val_amt < time_dataset['time'][-1]) and len(seen) != len(dataset['time'])):\n",
    "        idx = random.randint(0, len(dataset['file'])-1)\n",
    "        if idx not in seen:\n",
    "            #print(train_amt + test_amt + val_amt)\n",
    "            seen.add(idx)\n",
    "            if (test_amt < test_size):\n",
    "                test.add(dataset[\"file\"][idx])\n",
    "                test_amt += dataset[\"time\"][idx]\n",
    "            elif (train_amt < train_size):\n",
    "                train.add(dataset[\"file\"][idx])\n",
    "                train_amt += dataset[\"time\"][idx]\n",
    "            else:\n",
    "                val_seen = True\n",
    "                val.add(dataset[\"file\"][idx])\n",
    "                val_amt += dataset[\"time\"][idx]\n",
    "    if not val_seen:\n",
    "        val.add(dataset[\"file\"][0])\n",
    "        val_amt += dataset[\"time\"][0]\n",
    "    print(\"Train Time: \", train_amt, \"Number of files: \", len(train))\n",
    "    print(\"Test Time: \", test_amt, \"Number of files: \", len(test))\n",
    "    print(\"Val Time: \", val_amt, \"Number of files: \", len(val))\n",
    "    return train, test, val\n",
    "        \n",
    "#then see if we can stratify split.\n",
    "def tag_videos(Y, uids, time_dataset):\n",
    "    labels = {}\n",
    "    for i, f in enumerate(uids):\n",
    "        if f in labels:\n",
    "            labels[f][0].add(Y[i])\n",
    "        else:\n",
    "            time = 0\n",
    "            for i, x in enumerate(time_dataset['file']):\n",
    "                if x == f:\n",
    "                    time = time_dataset['time'][i][0]\n",
    "            labels[f] = {(Y[i])}, time\n",
    "    return labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04620072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time:  [625.84258503] Number of files:  55\n",
      "Test Time:  [411.35936508] Number of files:  39\n",
      "Val Time:  [9.41501134] Number of files:  1\n"
     ]
    }
   ],
   "source": [
    "train, test, val = split_data(X, Y, uids, time_dataset, train_size = 900, test_size = 400)\n",
    "#make sure to convert to np.arrays later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e080ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': [array([[ 1.4922979e-03, -1.9786218e-03,  2.0593621e-03, ...,\n",
       "          -5.4823677e-06,  7.5243502e-06, -6.2419749e-06],\n",
       "         [-1.3716071e-03,  1.3977840e-03, -1.2556884e-03, ...,\n",
       "           2.8330746e-06, -4.1192602e-06,  4.4225499e-06],\n",
       "         [ 1.0804265e-03, -1.1369591e-03,  1.1093493e-03, ...,\n",
       "           1.7529709e-06, -1.3599507e-06, -4.2460007e-07],\n",
       "         ...,\n",
       "         [ 3.2596031e-04, -7.9094520e-04,  1.0215285e-03, ...,\n",
       "           2.6602399e-06, -5.2387372e-06,  7.2160542e-06],\n",
       "         [-4.9243378e-04,  4.7261754e-04, -6.4715027e-04, ...,\n",
       "          -7.1201106e-07,  5.1395233e-07, -9.8188673e-07],\n",
       "         [ 1.2169620e-03, -9.1684214e-04,  3.2683619e-04, ...,\n",
       "           2.7038518e-06, -1.8826378e-06,  7.1760731e-08]], dtype=float32)],\n",
       " 'Y': [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,\n",
       "          1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  0,  1,  1,\n",
       "          1,  1,  1,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  8,  8,  8,  8,  2,\n",
       "          2,  2,  3,  3,  3,  3,  0,  1,  1,  1,  1,  0,  0,  0,  0,  1,  1,\n",
       "          1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  3,  3,  3,  0,  4,\n",
       "          4,  4,  4,  4,  5,  5,  6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
       "          8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  2,  2,  2,  3,\n",
       "          3,  3,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  0,  0,  0, 10, 10,\n",
       "         10, 10, 10,  8,  8,  8,  8,  8,  8,  8,  0,  0,  0,  3,  3,  3,  4,\n",
       "          4,  4,  4,  4,  5,  5,  5,  6,  6,  7,  7,  7,  7,  8,  8,  8,  8,\n",
       "          8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  2,  2,  2,  2,\n",
       "          3,  3,  3,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "          0, 10, 10, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0])],\n",
       " 'uids': ['16.wav']}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4fcc77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_time(X, fileidx, time_dataset, window_size):\n",
    "    time_file = time_dataset[\"time\"][fileidx][0]\n",
    "    frames_file = len(X)\n",
    "    return window_size * time_file / frames_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89b919c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one more step where we will window the datasets. \n",
    "#how much time is 88 timebins\n",
    "def window_spectrograms(data, time_dataset, window_size = 88, size=900):\n",
    "    X = []\n",
    "    Y = []\n",
    "    uids = []\n",
    "    seen = set()\n",
    "    seconds = 0\n",
    "    while (seconds < size):\n",
    "        fileidx = 0\n",
    "        if len(data[\"uids\"])>1:\n",
    "            fileidx = random.randint(0, len(data[\"uids\"])-1)\n",
    "        #print(fileidx)\n",
    "        #print(data[\"X\"])\n",
    "        idx = random.randint(0, data[\"X\"][fileidx].shape[0]-window_size-1)\n",
    "        timeidx = [x for x in range(len(time_dataset[\"file\"])) if time_dataset[\"file\"][x] == data[\"uids\"][fileidx]][0]\n",
    "        if (fileidx, idx) not in seen:\n",
    "            seen.add((fileidx, idx))\n",
    "            #print(fileidx, timeidx)\n",
    "            #print(data[\"uids\"][fileidx], time_dataset[\"file\"][timeidx], idx)\n",
    "            #frequency bins need to be capped or 0 padded.\n",
    "            X.append(data[\"X\"][fileidx][idx:idx+window_size, :])\n",
    "            Y.append(data[\"Y\"][fileidx][idx:idx+window_size])\n",
    "            uids.append(data[\"uids\"][fileidx] +\"_\"+str(idx))\n",
    "            seconds += get_window_time(data[\"X\"][fileidx], timeidx, time_dataset, window_size)\n",
    "    return {\"X\" : np.array(X), \"Y\" : np.array(Y), \"uids\" : np.array(uids)}\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4100d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = window_spectrograms(train, time_dataset, window_size = 88, size = 900)\n",
    "test_set = window_spectrograms(test, time_dataset, window_size = 88, size = 400)\n",
    "val_set = window_spectrograms(val, time_dataset, window_size = 88, size = 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1de4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_spectrograms(dataset):\n",
    "    X = []\n",
    "    for i in range(len(dataset[\"X\"])):\n",
    "        X.append(dataset[\"X\"][i].transpose())\n",
    "    dataset[\"X\"] = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5859f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_spectrograms(train_set)\n",
    "transpose_spectrograms(test_set)\n",
    "transpose_spectrograms(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4139c6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 1025, 88)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[\"X\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60f09e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((321, 1025, 88),\n",
       " (321, 88),\n",
       " array(['45.wav_98', '31.wav_35', '15.wav_284', '62.wav_5', '37.wav_303',\n",
       "        '16.wav_109', '93.wav_81', '75.wav_117', '86.wav_5', '45.wav_328',\n",
       "        '76.wav_288', '87.wav_181', '89.wav_194', '8.wav_85', '14.wav_104',\n",
       "        '28.wav_120', '16.wav_39', '7.wav_24', '9.wav_216', '51.wav_126',\n",
       "        '93.wav_198', '9.wav_243', '8.wav_90', '28.wav_14', '86.wav_106',\n",
       "        '86.wav_8', '53.wav_256', '30.wav_7', '20.wav_17', '64.wav_110',\n",
       "        '85.wav_374', '47.wav_171', '65.wav_242', '3.wav_244', '53.wav_36',\n",
       "        '90.wav_13', '57.wav_211', '55.wav_2', '30.wav_38', '93.wav_108',\n",
       "        '31.wav_186', '71.wav_181', '89.wav_83', '14.wav_92', '89.wav_220',\n",
       "        '7.wav_52', '14.wav_43', '16.wav_8', '21.wav_188', '67.wav_356',\n",
       "        '30.wav_246', '47.wav_22', '76.wav_219', '29.wav_305', '59.wav_1',\n",
       "        '4.wav_344', '36.wav_128', '21.wav_228', '44.wav_137',\n",
       "        '31.wav_178', '9.wav_7', '41.wav_218', '16.wav_190', '53.wav_233',\n",
       "        '30.wav_39', '1.wav_61', '14.wav_181', '72.wav_242', '65.wav_250',\n",
       "        '89.wav_155', '36.wav_89', '88.wav_286', '59.wav_139', '1.wav_259',\n",
       "        '41.wav_91', '91.wav_96', '62.wav_27', '66.wav_229', '24.wav_175',\n",
       "        '67.wav_165', '72.wav_188', '60.wav_49', '7.wav_82', '9.wav_11',\n",
       "        '72.wav_155', '41.wav_24', '15.wav_41', '11.wav_22', '30.wav_198',\n",
       "        '1.wav_116', '37.wav_236', '44.wav_111', '37.wav_103',\n",
       "        '37.wav_106', '7.wav_51', '1.wav_298', '11.wav_113', '66.wav_178',\n",
       "        '64.wav_169', '87.wav_131', '15.wav_305', '72.wav_294',\n",
       "        '90.wav_200', '51.wav_102', '75.wav_80', '86.wav_93', '72.wav_216',\n",
       "        '44.wav_40', '9.wav_52', '87.wav_56', '75.wav_0', '55.wav_129',\n",
       "        '7.wav_6', '11.wav_89', '21.wav_181', '9.wav_195', '62.wav_9',\n",
       "        '66.wav_225', '24.wav_195', '8.wav_140', '72.wav_40', '86.wav_3',\n",
       "        '75.wav_42', '79.wav_151', '37.wav_282', '30.wav_224', '21.wav_54',\n",
       "        '54.wav_224', '16.wav_127', '10.wav_180', '91.wav_2', '75.wav_95',\n",
       "        '84.wav_384', '56.wav_64', '36.wav_242', '73.wav_230', '36.wav_2',\n",
       "        '29.wav_273', '84.wav_382', '26.wav_141', '86.wav_38',\n",
       "        '56.wav_195', '60.wav_304', '59.wav_87', '31.wav_93', '36.wav_222',\n",
       "        '72.wav_235', '15.wav_352', '30.wav_209', '73.wav_279',\n",
       "        '26.wav_230', '31.wav_196', '56.wav_226', '90.wav_171',\n",
       "        '10.wav_111', '65.wav_111', '67.wav_331', '75.wav_145',\n",
       "        '55.wav_128', '53.wav_209', '16.wav_82', '8.wav_45', '28.wav_35',\n",
       "        '26.wav_232', '16.wav_121', '57.wav_77', '7.wav_39', '8.wav_13',\n",
       "        '67.wav_113', '79.wav_7', '9.wav_255', '41.wav_17', '93.wav_250',\n",
       "        '31.wav_14', '37.wav_298', '55.wav_17', '55.wav_195', '72.wav_126',\n",
       "        '88.wav_152', '90.wav_93', '16.wav_19', '26.wav_200', '55.wav_132',\n",
       "        '47.wav_310', '26.wav_240', '86.wav_33', '44.wav_126', '14.wav_46',\n",
       "        '25.wav_152', '7.wav_85', '4.wav_155', '45.wav_302', '89.wav_84',\n",
       "        '56.wav_19', '53.wav_238', '21.wav_114', '69.wav_30', '44.wav_47',\n",
       "        '41.wav_47', '67.wav_309', '8.wav_2', '44.wav_50', '25.wav_194',\n",
       "        '89.wav_77', '4.wav_85', '9.wav_115', '62.wav_79', '65.wav_61',\n",
       "        '88.wav_204', '54.wav_212', '60.wav_275', '36.wav_195', '7.wav_80',\n",
       "        '57.wav_2', '26.wav_24', '53.wav_40', '62.wav_61', '91.wav_126',\n",
       "        '25.wav_252', '75.wav_3', '60.wav_173', '47.wav_299', '9.wav_206',\n",
       "        '93.wav_211', '84.wav_355', '55.wav_101', '85.wav_60',\n",
       "        '73.wav_217', '9.wav_280', '28.wav_90', '25.wav_90', '37.wav_74',\n",
       "        '24.wav_84', '15.wav_286', '28.wav_144', '79.wav_32', '79.wav_152',\n",
       "        '62.wav_66', '86.wav_6', '26.wav_49', '37.wav_265', '88.wav_95',\n",
       "        '65.wav_266', '55.wav_207', '16.wav_63', '31.wav_207',\n",
       "        '25.wav_231', '76.wav_90', '31.wav_127', '69.wav_14', '30.wav_69',\n",
       "        '66.wav_249', '11.wav_1', '4.wav_75', '59.wav_223', '67.wav_175',\n",
       "        '36.wav_109', '59.wav_312', '88.wav_185', '88.wav_282',\n",
       "        '53.wav_141', '4.wav_164', '72.wav_206', '67.wav_272', '55.wav_43',\n",
       "        '7.wav_93', '37.wav_196', '15.wav_179', '31.wav_57', '86.wav_59',\n",
       "        '75.wav_23', '51.wav_69', '67.wav_27', '47.wav_291', '26.wav_25',\n",
       "        '62.wav_164', '30.wav_271', '73.wav_186', '30.wav_106',\n",
       "        '3.wav_258', '45.wav_29', '67.wav_323', '47.wav_316', '9.wav_74',\n",
       "        '90.wav_115', '71.wav_135', '73.wav_129', '72.wav_264',\n",
       "        '10.wav_30', '88.wav_125', '7.wav_4', '76.wav_259', '85.wav_144',\n",
       "        '73.wav_81', '31.wav_37', '7.wav_40', '45.wav_2', '25.wav_247',\n",
       "        '89.wav_87', '3.wav_263', '21.wav_11', '53.wav_34', '66.wav_54',\n",
       "        '21.wav_189', '53.wav_120', '67.wav_84', '26.wav_218', '86.wav_51',\n",
       "        '30.wav_136', '57.wav_270', '45.wav_138', '9.wav_266', '21.wav_55',\n",
       "        '59.wav_62', '75.wav_90', '90.wav_122', '20.wav_114', '89.wav_33',\n",
       "        '16.wav_185', '20.wav_108', '45.wav_48'], dtype='<U10'))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[\"X\"].shape, train_set[\"Y\"].shape, train_set[\"uids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76b5ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = X[ind_train, :, :, np.newaxis], X[ind_test, :, :, np.newaxis]\n",
    "#Y_train, Y_test = Y[ind_train], Y[ind_test]\n",
    "#uids_train, uids_test = uids[ind_train], uids[ind_test]\n",
    "#del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fefd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e691b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(train[\"Y\"]), Counter(test[\"Y\"]), Counter(val[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242fbbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74c0f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomAudioDataset(train_set[\"X\"], train_set[\"Y\"], train_set[\"uids\"])\n",
    "test_dataset = CustomAudioDataset(test_set[\"X\"], test_set[\"Y\"], test_set[\"uids\"])\n",
    "val_dataset = CustomAudioDataset(val_set[\"X\"], val_set[\"Y\"], val_set[\"uids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e401cebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.2577205e-04, -8.6027541e-04,  9.1980572e-04, ...,\n",
       "         -6.6030415e-04,  4.8896659e-04, -6.3845934e-04],\n",
       "        [-6.0312665e-04,  5.9768459e-04, -1.1660788e-03, ...,\n",
       "          7.0099387e-04, -9.1611681e-04,  4.5346751e-04],\n",
       "        [ 8.9210167e-04, -1.8320972e-04,  9.6504699e-04, ...,\n",
       "          1.6358160e-04,  4.5042337e-04,  3.4870682e-04],\n",
       "        ...,\n",
       "        [-6.3171291e-07,  2.9031062e-06, -3.8344859e-07, ...,\n",
       "          4.2814228e-09,  4.2057928e-07,  2.7856167e-08],\n",
       "        [-6.8157300e-07, -1.8386851e-06,  1.5512649e-06, ...,\n",
       "          1.9216466e-06,  5.0112897e-07,  2.2383642e-06],\n",
       "        [ 3.3002002e-06,  3.3381647e-07, -2.4332121e-06, ...,\n",
       "         -2.3656175e-06, -1.6768818e-06, -3.0636163e-06]], dtype=float32),\n",
       " array([ 1,  1,  1,  1,  0,  0,  0,  0,  2,  2,  2,  2,  3,  3,  3,  0,  1,\n",
       "         1,  1,  1,  1,  8,  8,  8,  8,  8,  8,  2,  2,  2,  2,  0,  0,  0,\n",
       "         4,  4,  4,  4,  4,  5,  5,  6,  6,  7,  7,  7,  7,  0,  8,  8,  8,\n",
       "         8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  2,  2,  2,\n",
       "         3,  3,  3,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  0,  0, 10, 10,\n",
       "        10, 10,  0]),\n",
       " '45.wav_98')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be66ec5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = set()\n",
    "for lab in Y:\n",
    "    for idx in lab:\n",
    "        all_labels.add(idx)\n",
    "all_labels\n",
    "#labels = tag_videos(Y, uids, time_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68e2f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_files = sorted(set(train[\"uids\"]))\n",
    "#test_files = sorted(set(test[\"uids\"]))\n",
    "#val_files = sorted(set(val[\"uids\"]))\n",
    "#total count of each label.\n",
    "#total length in seconds.\n",
    "#calculate these metrics after converting to py file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c226cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to actually normalize # These are just percentages\n",
    "def get_percent_label_metrics(labels, all_labels):\n",
    "    total_label_counts = {str(x): 0 for x in all_labels}\n",
    "    for f in labels:\n",
    "        for i in labels[f][0]:\n",
    "            total_label_counts[str(i)] += 1\n",
    "    percent = [total_label_counts[x]/len(labels) for x in total_label_counts]\n",
    "    return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce8abace",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-62f93a515f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_percent_label_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "get_percent_label_metrics(labels, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "129e9855",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-c4d7435fefea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_percent_label_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "train_labels = {x: labels[x] for x in labels if x in train_files}\n",
    "print(len(train_labels))\n",
    "get_percent_label_metrics(train_labels, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6eb244ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0a34db1448dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_percent_label_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "test_labels = {x: labels[x] for x in labels if x in test_files}\n",
    "print(len(test_labels))\n",
    "get_percent_label_metrics(test_labels, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "205facb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-cd10953f2181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_files\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_percent_label_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "val_labels = {x: labels[x] for x in labels if x in val_files}\n",
    "print(len(val_labels))\n",
    "get_percent_label_metrics(val_labels, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "76cf4444",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 339 is out of bounds for axis 0 with size 339",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-cb9e9f22e2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtotal_label_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-73878834f32a>\u001b[0m in \u001b[0;36mtag_videos\u001b[0;34m(Y, uids, time_dataset)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 339 is out of bounds for axis 0 with size 339"
     ]
    }
   ],
   "source": [
    "labels = tag_videos(Y, uids, time_dataset)\n",
    "total_label_counts = {str(x): 0 for x in all_labels}\n",
    "\n",
    "for f in labels:\n",
    "    for i in labels[f][0]:\n",
    "        total_label_counts[str(i)] += 1\n",
    "total_label_counts, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e7e5ea2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_label_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-2ac3bc6d8ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtotal_label_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtotal_label_counts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnormed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_label_counts' is not defined"
     ]
    }
   ],
   "source": [
    "normed = [total_label_counts[x]/len(labels) for x in total_label_counts]\n",
    "normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64e64699",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-a2073da8cd39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#get size depending on lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "x = np.array([x for x in labels])\n",
    "y = np.array([labels[x] for x in labels])\n",
    "#get size depending on lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "af8b923e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 1025)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train[\"X\"][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e07d23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 88)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "763c8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(history):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(history[\"loss\"])\n",
    "    plt.plot(history[\"val_loss\"])\n",
    "    plt.legend([\"loss\", \"val_loss\"])\n",
    "    plt.savefig('loss.png')\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(history[\"acc\"])\n",
    "    plt.plot(history[\"val_acc\"])\n",
    "    plt.legend([\"acc\", \"val_acc\"])\n",
    "    plt.savefig('acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c5014e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_error(pred, actual):\n",
    "    if len(pred) != len(actual):\n",
    "        Print(\"Incorrect Lengths: \", len(pred), len(actual))\n",
    "        return 0\n",
    "    match_up = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == actual[i]:\n",
    "            match_up += 1\n",
    "    return match_up#/len(pred)\n",
    "# This only matters if things are in the correct order. Can I split by video file?\n",
    "#should be done for each window and then summed together. \n",
    "def syllable_edit_distance(pred, actual):\n",
    "    if len(pred) != len(actual):\n",
    "        Print(\"Incorrect Lengths: \", len(pred), len(actual))\n",
    "        return 0 \n",
    "    distances = range(len(pred) + 1)\n",
    "    for i2, c2 in enumerate(actual):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(pred):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]#/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d185f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "TweetyNet(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2dTF(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=(8, 1), stride=(8, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2dTF(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=(8, 1), stride=(8, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (rnn): LSTM(1024, 1024, bidirectional=True)\n",
      "  (fc): Linear(in_features=2048, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "#make the input look nicer\n",
    "def CreateTweetyNet(device, num_classes, input_shape):\n",
    "    network = TweetyNet(num_classes = num_classes, \n",
    "             input_shape = input_shape,\n",
    "             padding='same',\n",
    "             conv1_filters=32,\n",
    "             conv1_kernel_size=(5, 5), \n",
    "             conv2_filters=64,\n",
    "             conv2_kernel_size=(5, 5), \n",
    "             pool1_size=(8, 1), \n",
    "             pool1_stride=(8, 1), \n",
    "             pool2_size=(8, 1), \n",
    "             pool2_stride=(8, 1), \n",
    "             hidden_size=None,\n",
    "             rnn_dropout=0.,\n",
    "             num_layers=1\n",
    "        ) \n",
    "    model = network.to(device)\n",
    "    print(model)\n",
    "    return model\n",
    "model = CreateTweetyNet(device, len(all_labels), input_shape = (1, 1025, 88))\n",
    "def reset_weights(the_model):\n",
    "    for name, module in the_model.named_children():\n",
    "        if hasattr(module, 'reset_parameters'):\n",
    "            print('resetting ', name)\n",
    "            module.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03f83f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = CustomAudioDataset(X_train, Y_train, uids_train)\n",
    "#test_dataset = CustomAudioDataset(X_test, Y_test, uids_test)\n",
    "#val_dataset = CustomAudioDataset(X_val, Y_val, uids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6b58be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, device, train_loader, val_loader, window_size, criterion, optimizer, scheduler, epoch):\n",
    "    history = {\"loss\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"acc\": [],\n",
    "               \"val_acc\": [],\n",
    "               \"edit_distance\" : [],\n",
    "               \"val_edit_distance\" : []\n",
    "               }\n",
    "    for e in range(epoch):  # loop over the dataset multiple times\n",
    "        print(\"Start of epoch:\", e)\n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        correct = 0.0\n",
    "        edit_distance = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels, _ = data  # , input_lengths, label_lengths = data\n",
    "            #labels = labels.reshape(1, labels.shape[0], labels.shape[1])\n",
    "            inputs = inputs.reshape(inputs.shape[0], 1, inputs.shape[1], inputs.shape[2])\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #print(inputs.shape, labels.shape)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            output = model(inputs, inputs.shape[0], labels.shape[0])\n",
    "\n",
    "\n",
    "            #print(output.shape)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            # get statistics\n",
    "            running_loss += loss.item()\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            #print(output.shape)\n",
    "            correct += (output == labels).float().sum()\n",
    "            for j in range(len(labels)):\n",
    "                edit_distance += syllable_edit_distance(output[j], labels[j])\n",
    "            # print update\n",
    "            if i % 10 == 9:  # print every 100 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %(e + 1, i + 1, running_loss / 2000))\n",
    "        history[\"loss\"].append(running_loss)\n",
    "        history[\"acc\"].append(100 * correct / (len(train_loader.dataset) * window_size))\n",
    "        history[\"edit_distance\"].append(edit_distance / (len(train_loader.dataset) * window_size))\n",
    "        validation_step(model, device, val_loader, window_size, criterion, history)\n",
    "    print('Finished Training')\n",
    "    return history\n",
    "\n",
    "def validation_step(model, device, val_loader, window_size, criterion, history):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0.0\n",
    "        val_edit_distance = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels, _ = data  # , input_lengths, label_lengths = data\n",
    "            inputs = inputs.reshape(inputs.shape[0], 1, inputs.shape[1], inputs.shape[2])\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #print(inputs.shape, labels.shape)\n",
    "            # forward + backward + optimize\n",
    "            output = model(inputs, inputs.shape[0], labels.shape[0])\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            # get statistics\n",
    "            val_loss += loss.item()\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            #print(output.shape)\n",
    "            print((output == labels).shape, (output == labels).float().sum())\n",
    "            val_correct += (output == labels).float().sum()\n",
    "            for j in range(len(labels)):\n",
    "                val_edit_distance += syllable_edit_distance(output[j], labels[j])\n",
    "            print(val_edit_distance)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(100 * val_correct / (len(val_loader.dataset) * window_size))\n",
    "        history[\"val_edit_distance\"].append(val_edit_distance / (len(val_loader.dataset) * window_size))\n",
    "\n",
    "def testing_step(model, device, window_size, test_loader):\n",
    "    predictions = pd.DataFrame()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs, labels, uids = data  # , input_lengths, label_lengths = data\n",
    "            inputs = inputs.reshape(inputs.shape[0], 1, inputs.shape[1], inputs.shape[2])\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #print(inputs.shape, labels.shape)\n",
    "            # forward + backward + optimize\n",
    "            output = model(inputs, inputs.shape[0], labels.shape[0])\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            # get statistics\n",
    "            temp_uids = []\n",
    "            for u in uids:\n",
    "                for j in range(window_size):\n",
    "                    temp_uids.append(u + \"_\" + str(j)) \n",
    "            uids = np.array(temp_uids)\n",
    "            d = {\"uid\": uids.flatten(), \"pred\": output.flatten(), \"label\": labels.flatten()}\n",
    "            new_preds = pd.DataFrame(d)\n",
    "            predictions = predictions.append(new_preds)\n",
    "    print('Finished Testing')\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1def0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(model, device, train_dataset, val_dataset, test_dataset,\n",
    "                   train = True, fineTuning = False, save_me = False, finetune_path = None):\n",
    "    batch_size = 64\n",
    "    lr = .005\n",
    "    epochs = 1\n",
    "\n",
    "    if train:\n",
    "        if fineTuning:\n",
    "            model.load_weights(finetune_path)\n",
    "        train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(params=model.parameters())\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                        max_lr=lr,\n",
    "                                                        steps_per_epoch=int(len(train_data_loader)),\n",
    "                                                        epochs=epochs,\n",
    "                                                        anneal_strategy='linear')\n",
    "        start_time = datetime.datetime.now()\n",
    "        history = training_step(model, device, train_data_loader, val_data_loader, 88, criterion, optimizer, scheduler,\n",
    "                                    epochs)\n",
    "        end_time = datetime.datetime.now()\n",
    "        \n",
    "        test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_out = testing_step(model, device, 88, test_data_loader)\n",
    "        \n",
    "        if save_me:\n",
    "            date_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            torch.save(model.state_dict(), f\"model_weights-{date_str}.h5\")\n",
    "        print_results(history)\n",
    "        return history, test_out, start_time, end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06eefd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "673a19c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch: 0\n",
      "torch.Size([24, 88]) tensor(324.)\n",
      "1788.0\n",
      "Finished Training\n",
      "Finished Testing\n",
      "Time elapsed: 0:01:34.177378\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, test_out, start_time, end_time = train_pipeline(model, device, train_dataset, val_dataset, test_dataset)\n",
    "print(\"Time elapsed:\", end_time - start_time)\n",
    "#is missing a dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8bb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "test_out = testing_step(model, device, 88, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294198c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffac8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e223a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(hist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1706223",
   "metadata": {},
   "source": [
    "Evaluation:\n",
    "Calculate frame error\n",
    "And syllable rate error (edit distance) (levenshtien distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_error(\"hat\", \"mft\"), syllable_edit_distance(\"hcat\", \"chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedfd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First calculate total time "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
