{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75845ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e665e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species_list(num_species=-1):\n",
    "    #print(\"getting species list\")\n",
    "    #get page of all xento-canto species\n",
    "    url = 'https://xeno-canto.org/collection/species/all'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text)\n",
    "    species_table = soup.find_all(\"table\", {\"class\": \"results\"})[0]\n",
    "    \n",
    "    #get headers of table\n",
    "    headers = []\n",
    "    for i in species_table.find_all('thead'):\n",
    "         title = i.text\n",
    "         headers.append(title)\n",
    "    headers = headers[0].strip().split(\"\\n\")\n",
    "    \n",
    "    #add header for url and create DF\n",
    "    headers.append('url')\n",
    "    species_list = pd.DataFrame(columns = headers)\n",
    "    \n",
    "    #Get data from each row\n",
    "    for j in species_table.find_all('tr'):\n",
    "         #get row data\n",
    "         row_data = j.find_all('td')\n",
    "        \n",
    "         #get all text from row\n",
    "         row = [i.text for i in row_data]\n",
    "        \n",
    "         #get the link\n",
    "         row.append(row_data[0].a[\"href\"])\n",
    "        \n",
    "         #add to dataframe\n",
    "         length = len(species_list)\n",
    "         species_list.loc[length] = row\n",
    "\n",
    "    #Decide to return full list or do RS     \n",
    "    if (num_species == -1 or num_species > species_list.shape[0]):\n",
    "        return species_list\n",
    "    return species_list.sample(num_species).reset_index(drop=True)\n",
    "\n",
    "#get_species_list()\n",
    "#test1 = get_species_list(5)\n",
    "#test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028510c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species_data(link_to_XC):\n",
    "    #print(\"getting species file metadata for: \" + link_to_XC)\n",
    "    #get soup for Species\n",
    "    url = 'https://xeno-canto.org' + link_to_XC\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "    species_table = soup.find_all(\"table\", {\"class\": \"results\"})[0]\n",
    "    \n",
    "    # Obtain every title of columns with tag <th>\n",
    "    headers = []\n",
    "    for i in species_table.find_all('thead'):\n",
    "     title = i.text\n",
    "     headers.append(title)\n",
    "\n",
    "    headers = headers[0].strip()\n",
    "    headers = headers.split(\"\\n\")\n",
    "    headers[1] = \"Common name / Scientific\"\n",
    "    headers.append(\"copyright\")\n",
    "    headers.append(\"filename\")\n",
    "    headers.append(\"download url\")\n",
    "\n",
    "\n",
    "    species_list = pd.DataFrame(columns = headers[1:])\n",
    "    \n",
    "    \n",
    "    page_count = 1\n",
    "    while len(species_table.find_all('tr')) != 1:\n",
    "        \n",
    "        #print(len(species_table.find_all('tr')))\n",
    "        \n",
    "        #Get data from each row\n",
    "        for j in species_table.find_all('tr'):\n",
    "            #get row data\n",
    "            row_data = j.find_all('td')\n",
    "\n",
    "            if (row_data == []):\n",
    "                   continue\n",
    "\n",
    "            #print(row_data) \n",
    "            #get all text from row\n",
    "            row = [i.text.strip() for i in row_data][1:]\n",
    "\n",
    "            #get copyright, download link and filename\n",
    "            copyright = row_data[12].a.span[\"title\"]\n",
    "            try:\n",
    "                 filename = row_data[11].a[\"download\"]\n",
    "            except:\n",
    "                filename = \"PROTECTED SPECIES\"\n",
    "            download_url = row_data[11].a[\"href\"]\n",
    "            row.append(copyright)\n",
    "            row.append(filename)\n",
    "            row.append(download_url)\n",
    "\n",
    "            #add to dataframe\n",
    "            length = len(species_list)\n",
    "            species_list.loc[length] = row\n",
    "        \n",
    "        ## Get data for next page of audio data\n",
    "        page_count += 1\n",
    "        url = 'https://xeno-canto.org' + link_to_XC + \"?pg=\" + str(page_count)\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        species_table = soup.find_all(\"table\", {\"class\": \"results\"})[0]\n",
    "    return species_list\n",
    "\n",
    "#test2 = get_species_data(test1.iloc[0][\"url\"])\n",
    "#test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8792aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_by_url(file_data, download_folder):\n",
    "    print(file_data)\n",
    "    url = file_data[1]\n",
    "    url = 'https://xeno-canto.org' + url\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    path = download_folder+file_data[0]\n",
    "    open(path, \"wb\").write(r.content)\n",
    "    return path\n",
    "\n",
    "def download_data(species_df, num_of_files, download_folder):\n",
    "    print(\"downloading data\")\n",
    "    if (num_of_files != -1 and species_df.shape[0] > num_of_files):\n",
    "        species_df = species_df.sample(num_of_files, replace=False)\n",
    "    species_df[\"file_location\"] = species_df[[\"filename\",\"download url\"]].apply(download_by_url,axis=1, args=(tuple([download_folder])))\n",
    "    return species_df\n",
    "\n",
    "#download_data(test2, 100, \"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729ea3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_xento_canto_data(num_species, num_of_files, download_folder, species_list=pd.DataFrame()):\n",
    "    file_df = pd.DataFrame()\n",
    "    if (species_list.empty):\n",
    "        species_list = get_species_list(num_species)\n",
    "    for url in species_list[\"url\"]:\n",
    "        try:\n",
    "            species_files = get_species_data(url)\n",
    "            temp_file_df = download_data(species_files, num_of_files, download_folder)\n",
    "            if (file_df.empty):\n",
    "                file_df = temp_file_df.reset_index(drop=True)\n",
    "            else:\n",
    "                file_df = file_df.append(temp_file_df.reset_index(drop=True)).reset_index(drop=True)\n",
    "        except Exception as e:\n",
    "            print(url + \" did not download\")\n",
    "            print(e)\n",
    "    return file_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe257286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata = download_xento_canto_data(-1, -1, \"./data/\")\n",
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37cb7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata.to_csv(\"./metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_species_list()\n",
    "test1 = get_species_list(-1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3a4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "file_df = pd.DataFrame()\n",
    "for url in tqdm(test1[\"url\"]):\n",
    "    try:\n",
    "        species_files = get_species_data(url)\n",
    "    except:\n",
    "        continue\n",
    "    if (file_df.empty):\n",
    "        file_df = species_files.reset_index(drop=True)\n",
    "    else:\n",
    "        file_df = file_df.append(species_files.reset_index(drop=True)).reset_index(drop=True)\n",
    "file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0215d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "madreDeDios_species = pd.read_csv(\"C:/Users/Siloux/Downloads/MadreDeDiosBirdsXCList - MadreDeDiosBirdsXCList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b230865",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = pd.read_csv(\"./all_meta_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bd295",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df[\"Common\"] = file_df[\"Common name / Scientific\"].apply(lambda x: x.split(\" \")[0] + \" \"+ x.split(\" \")[1])\n",
    "file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e8c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_MDD_XC = file_df.merge(madreDeDios_species, left_on=\"Common\", right_on=\"Common\")\n",
    "file_MDD_XC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_MDD_XC.groupby(\"Common\").count().sort_values(by=\"Length\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d487ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.set_index(\"Common\").loc[\"\\n\\nOrange-cheeked Parrot\\n\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://xeno-canto.org/species/Pyrilia-barrabandi\"\n",
    "#get_species_data(\"/species/Pyrilia-barrabandi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d1215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
